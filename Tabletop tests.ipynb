{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e04cccb-a422-45dc-9a81-158014653232",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Documents/D&D/Codes/merged_card_data.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c8363c-7b25-4beb-9e9b-1c24732622e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = None\n",
    "while a:\n",
    "    print(\"test\")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c93f1b19-fbad-45c3-8621-eb95c6068a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "#import pygame\n",
    "import os\n",
    "import time\n",
    "from scipy.stats import hypergeom, tstd\n",
    "import itertools\n",
    "import torch.nn.init as init\n",
    "from torch import nn, optim\n",
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f62e592-678c-4688-95bb-3eeac856ccd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.3.0 (SDL 2.24.2, Python 3.10.10)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (gamedata.py, line 283)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[0;32m~\\Anaconda3\\envs\\image_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3460\u001b[0m in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[0;32mIn[2], line 1\u001b[0m\n    from maputil import generate_minimap, Minimap #Function that generates three lists: nodes (descriptions of events at each location), map (similar to nodes, with a 1 if a node is present and 0 if absent), and connections (a list of arrays describing a sufficient and non-intersecting set of connections from each layer to the next)\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m~\\Documents\\GitHub\\tabletop_cardgame\\maputil.py:8\u001b[1;36m\n\u001b[1;33m    from gamedata import worlds\u001b[1;36m\n",
      "\u001b[1;36m  File \u001b[1;32m~\\Documents\\GitHub\\tabletop_cardgame\\gamedata.py:283\u001b[1;36m\u001b[0m\n\u001b[1;33m    \"exclusive_params\" : {\"color\": True}#Should be monoblue only\u001b[0m\n\u001b[1;37m                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "from maputil import generate_minimap, Minimap #Function that generates three lists: nodes (descriptions of events at each location), map (similar to nodes, with a 1 if a node is present and 0 if absent), and connections (a list of arrays describing a sufficient and non-intersecting set of connections from each layer to the next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0177f3e1-1ef7-4ebf-be45-09e6136f687b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiutil import land_policy_net, deck_costs\n",
    "from cardutil import select_cards, shortened_card_data, sample_deck #Select cards picks a selection of n random cards from the array shortened_card_data, based on dictionaries of positive and negative parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b6f3e76-8b56-4c81-85d3-b1463e0d836f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'set': ['bfz'],\n",
       "  'rarity': ['rare'],\n",
       "  'color': [],\n",
       "  'mana_cost': ['6'],\n",
       "  'mana_symbols': [],\n",
       "  'name': ['Conduit of Ruin'],\n",
       "  'cmc': [6.0],\n",
       "  'card_type': ['Creature'],\n",
       "  'subtypes': ['Eldrazi'],\n",
       "  'keywords': [],\n",
       "  'watermark': [],\n",
       "  'oracle_text': ['When you cast this spell, you may search your library for a colorless creature card with mana value 7 or greater, reveal it, then shuffle and put that card on top.\\nThe first creature spell you cast each turn costs {2} less to cast.'],\n",
       "  'legend': [False]},\n",
       " {'set': ['shm'],\n",
       "  'rarity': ['common'],\n",
       "  'color': [],\n",
       "  'mana_cost': ['2'],\n",
       "  'mana_symbols': [],\n",
       "  'name': ['Pili-Pala'],\n",
       "  'cmc': [2.0],\n",
       "  'card_type': ['Artifact', 'Creature'],\n",
       "  'subtypes': ['Scarecrow'],\n",
       "  'keywords': ['Flying'],\n",
       "  'watermark': [],\n",
       "  'oracle_text': ['Flying\\n{2}, {Q}: Add one mana of any color. ({Q} is the untap symbol.)'],\n",
       "  'legend': [False]},\n",
       " {'set': ['m11'],\n",
       "  'rarity': ['uncommon'],\n",
       "  'color': [],\n",
       "  'mana_cost': ['1'],\n",
       "  'mana_symbols': [],\n",
       "  'name': ['Voltaic Key'],\n",
       "  'cmc': [1.0],\n",
       "  'card_type': ['Artifact'],\n",
       "  'subtypes': [],\n",
       "  'keywords': [],\n",
       "  'watermark': [],\n",
       "  'oracle_text': ['{1}, {T}: Untap target artifact.'],\n",
       "  'legend': [False]},\n",
       " {'set': ['bfz'],\n",
       "  'rarity': ['common'],\n",
       "  'color': ['G'],\n",
       "  'mana_cost': ['2', 'G'],\n",
       "  'mana_symbols': ['G'],\n",
       "  'name': ['Tajuru Stalwart'],\n",
       "  'cmc': [3.0],\n",
       "  'card_type': ['Creature'],\n",
       "  'subtypes': ['Elf', 'Scout', 'Ally'],\n",
       "  'keywords': ['Converge'],\n",
       "  'watermark': [],\n",
       "  'oracle_text': ['Converge â€” Tajuru Stalwart enters the battlefield with a +1/+1 counter on it for each color of mana spent to cast it.'],\n",
       "  'legend': [False]},\n",
       " {'set': ['m11'],\n",
       "  'rarity': ['rare'],\n",
       "  'color': ['G'],\n",
       "  'mana_cost': ['1', 'G', 'G'],\n",
       "  'mana_symbols': ['G', 'G'],\n",
       "  'name': ['Elvish Archdruid'],\n",
       "  'cmc': [3.0],\n",
       "  'card_type': ['Creature'],\n",
       "  'subtypes': ['Elf', 'Druid'],\n",
       "  'keywords': [],\n",
       "  'watermark': [],\n",
       "  'oracle_text': ['Other Elf creatures you control get +1/+1.\\n{T}: Add {G} for each Elf you control.'],\n",
       "  'legend': [False]},\n",
       " {'set': ['bng'],\n",
       "  'rarity': ['rare'],\n",
       "  'color': ['G'],\n",
       "  'mana_cost': ['2', 'G'],\n",
       "  'mana_symbols': ['G'],\n",
       "  'name': ['Scourge of Skola Vale'],\n",
       "  'cmc': [3.0],\n",
       "  'card_type': ['Creature'],\n",
       "  'subtypes': ['Hydra'],\n",
       "  'keywords': ['Trample'],\n",
       "  'watermark': [],\n",
       "  'oracle_text': [\"Trample\\nScourge of Skola Vale enters the battlefield with two +1/+1 counters on it.\\n{T}, Sacrifice another creature: Put a number of +1/+1 counters on Scourge of Skola Vale equal to the sacrificed creature's toughness.\"],\n",
       "  'legend': [False]},\n",
       " {'set': ['gtc'],\n",
       "  'rarity': ['common'],\n",
       "  'color': ['G'],\n",
       "  'mana_cost': ['G'],\n",
       "  'mana_symbols': ['G'],\n",
       "  'name': ['Burst of Strength'],\n",
       "  'cmc': [1.0],\n",
       "  'card_type': ['Instant'],\n",
       "  'subtypes': [],\n",
       "  'keywords': [],\n",
       "  'watermark': [],\n",
       "  'oracle_text': ['Put a +1/+1 counter on target creature and untap it.'],\n",
       "  'legend': [False]},\n",
       " {'set': ['mor'],\n",
       "  'rarity': ['rare'],\n",
       "  'color': ['G'],\n",
       "  'mana_cost': ['1', 'G'],\n",
       "  'mana_symbols': ['G'],\n",
       "  'name': ['Cream of the Crop'],\n",
       "  'cmc': [2.0],\n",
       "  'card_type': ['Enchantment'],\n",
       "  'subtypes': [],\n",
       "  'keywords': [],\n",
       "  'watermark': [],\n",
       "  'oracle_text': [\"Whenever a creature enters the battlefield under your control, you may look at the top X cards of your library, where X is that creature's power. If you do, put one of those cards on top of your library and the rest on the bottom of your library in any order.\"],\n",
       "  'legend': [False]},\n",
       " {'set': ['ala'],\n",
       "  'rarity': ['common'],\n",
       "  'color': ['G'],\n",
       "  'mana_cost': ['2', 'G'],\n",
       "  'mana_symbols': ['G'],\n",
       "  'name': ['Court Archers'],\n",
       "  'cmc': [3.0],\n",
       "  'card_type': ['Creature'],\n",
       "  'subtypes': ['Human', 'Archer'],\n",
       "  'keywords': ['Reach', 'Exalted'],\n",
       "  'watermark': [],\n",
       "  'oracle_text': ['Reach (This creature can block creatures with flying.)\\nExalted (Whenever a creature you control attacks alone, that creature gets +1/+1 until end of turn.)'],\n",
       "  'legend': [False]},\n",
       " {'set': ['roe'],\n",
       "  'rarity': ['common'],\n",
       "  'color': ['G'],\n",
       "  'mana_cost': ['3', 'G'],\n",
       "  'mana_symbols': ['G'],\n",
       "  'name': [\"Kozilek's Predator\"],\n",
       "  'cmc': [4.0],\n",
       "  'card_type': ['Creature'],\n",
       "  'subtypes': ['Eldrazi', 'Drone'],\n",
       "  'keywords': [],\n",
       "  'watermark': [],\n",
       "  'oracle_text': ['When Kozilek\\'s Predator enters the battlefield, create two 0/1 colorless Eldrazi Spawn creature tokens. They have \"Sacrifice this creature: Add {C}.\"'],\n",
       "  'legend': [False]},\n",
       " {'set': ['roe'],\n",
       "  'rarity': ['uncommon'],\n",
       "  'color': ['G'],\n",
       "  'mana_cost': ['4', 'G', 'G', 'G'],\n",
       "  'mana_symbols': ['G', 'G', 'G'],\n",
       "  'name': ['Pelakka Wurm'],\n",
       "  'cmc': [7.0],\n",
       "  'card_type': ['Creature'],\n",
       "  'subtypes': ['Wurm'],\n",
       "  'keywords': ['Trample'],\n",
       "  'watermark': [],\n",
       "  'oracle_text': ['Trample\\nWhen Pelakka Wurm enters the battlefield, you gain 7 life.\\nWhen Pelakka Wurm dies, draw a card.'],\n",
       "  'legend': [False]},\n",
       " {'set': ['nph'],\n",
       "  'rarity': ['common'],\n",
       "  'color': ['G'],\n",
       "  'mana_cost': ['1', 'G', 'G'],\n",
       "  'mana_symbols': ['G', 'G'],\n",
       "  'name': ['Viridian Betrayers'],\n",
       "  'cmc': [3.0],\n",
       "  'card_type': ['Creature'],\n",
       "  'subtypes': ['Phyrexian', 'Elf', 'Warrior'],\n",
       "  'keywords': [],\n",
       "  'watermark': ['phyrexian'],\n",
       "  'oracle_text': ['Viridian Betrayers has infect as long as an opponent is poisoned. (It deals damage to creatures in the form of -1/-1 counters and to players in the form of poison counters.)'],\n",
       "  'legend': [False]},\n",
       " {'set': ['som'],\n",
       "  'rarity': ['uncommon'],\n",
       "  'color': [],\n",
       "  'mana_cost': ['2'],\n",
       "  'mana_symbols': [],\n",
       "  'name': ['Necropede'],\n",
       "  'cmc': [2.0],\n",
       "  'card_type': ['Artifact', 'Creature'],\n",
       "  'subtypes': ['Phyrexian', 'Insect'],\n",
       "  'keywords': ['Infect'],\n",
       "  'watermark': ['phyrexian'],\n",
       "  'oracle_text': ['Infect (This creature deals damage to creatures in the form of -1/-1 counters and to players in the form of poison counters.)\\nWhen Necropede dies, you may put a -1/-1 counter on target creature.'],\n",
       "  'legend': [False]},\n",
       " {'set': ['ogw'],\n",
       "  'rarity': ['common'],\n",
       "  'color': ['G'],\n",
       "  'mana_cost': ['3', 'G'],\n",
       "  'mana_symbols': ['G'],\n",
       "  'name': ['Saddleback Lagac'],\n",
       "  'cmc': [4.0],\n",
       "  'card_type': ['Creature'],\n",
       "  'subtypes': ['Lizard'],\n",
       "  'keywords': ['Support'],\n",
       "  'watermark': [],\n",
       "  'oracle_text': ['When Saddleback Lagac enters the battlefield, support 2. (Put a +1/+1 counter on each of up to two other target creatures.)'],\n",
       "  'legend': [False]},\n",
       " {'set': ['ala'],\n",
       "  'rarity': ['common'],\n",
       "  'color': ['G'],\n",
       "  'mana_cost': ['G'],\n",
       "  'mana_symbols': ['G'],\n",
       "  'name': ['Wild Nacatl'],\n",
       "  'cmc': [1.0],\n",
       "  'card_type': ['Creature'],\n",
       "  'subtypes': ['Cat', 'Warrior'],\n",
       "  'keywords': [],\n",
       "  'watermark': [],\n",
       "  'oracle_text': ['Wild Nacatl gets +1/+1 as long as you control a Mountain.\\nWild Nacatl gets +1/+1 as long as you control a Plains.'],\n",
       "  'legend': [False]},\n",
       " {'set': ['roe'],\n",
       "  'rarity': ['common'],\n",
       "  'color': [],\n",
       "  'mana_cost': ['8'],\n",
       "  'mana_symbols': [],\n",
       "  'name': [\"Ulamog's Crusher\"],\n",
       "  'cmc': [8.0],\n",
       "  'card_type': ['Creature'],\n",
       "  'subtypes': ['Eldrazi'],\n",
       "  'keywords': ['Annihilator'],\n",
       "  'watermark': [],\n",
       "  'oracle_text': [\"Annihilator 2 (Whenever this creature attacks, defending player sacrifices two permanents.)\\nUlamog's Crusher attacks each combat if able.\"],\n",
       "  'legend': [False]},\n",
       " {'set': ['m10'],\n",
       "  'rarity': ['common'],\n",
       "  'color': ['G'],\n",
       "  'mana_cost': ['1', 'G'],\n",
       "  'mana_symbols': ['G'],\n",
       "  'name': ['Regenerate'],\n",
       "  'cmc': [2.0],\n",
       "  'card_type': ['Instant'],\n",
       "  'subtypes': [],\n",
       "  'keywords': [],\n",
       "  'watermark': [],\n",
       "  'oracle_text': [\"Regenerate target creature. (The next time that creature would be destroyed this turn, it isn't. Instead tap it, remove all damage from it, and remove it from combat.)\"],\n",
       "  'legend': [False]},\n",
       " {'set': ['wwk'],\n",
       "  'rarity': ['rare'],\n",
       "  'color': ['G'],\n",
       "  'mana_cost': ['6', 'G', 'G'],\n",
       "  'mana_symbols': ['G', 'G'],\n",
       "  'name': ['Terastodon'],\n",
       "  'cmc': [8.0],\n",
       "  'card_type': ['Creature'],\n",
       "  'subtypes': ['Elephant'],\n",
       "  'keywords': [],\n",
       "  'watermark': [],\n",
       "  'oracle_text': ['When Terastodon enters the battlefield, you may destroy up to three target noncreature permanents. For each permanent put into a graveyard this way, its controller creates a 3/3 green Elephant creature token.'],\n",
       "  'legend': [False]},\n",
       " {'set': ['nph'],\n",
       "  'rarity': ['uncommon'],\n",
       "  'color': [],\n",
       "  'mana_cost': ['3'],\n",
       "  'mana_symbols': [],\n",
       "  'name': ['Shrine of Boundless Growth'],\n",
       "  'cmc': [3.0],\n",
       "  'card_type': ['Artifact'],\n",
       "  'subtypes': [],\n",
       "  'keywords': [],\n",
       "  'watermark': ['phyrexian'],\n",
       "  'oracle_text': ['At the beginning of your upkeep or whenever you cast a green spell, put a charge counter on Shrine of Boundless Growth.\\n{T}, Sacrifice Shrine of Boundless Growth: Add {C} for each charge counter on Shrine of Boundless Growth.'],\n",
       "  'legend': [False]},\n",
       " {'set': ['gtc'],\n",
       "  'rarity': ['common'],\n",
       "  'color': ['G'],\n",
       "  'mana_cost': ['1', 'G'],\n",
       "  'mana_symbols': ['G'],\n",
       "  'name': ['Greenside Watcher'],\n",
       "  'cmc': [2.0],\n",
       "  'card_type': ['Creature'],\n",
       "  'subtypes': ['Elf', 'Druid'],\n",
       "  'keywords': [],\n",
       "  'watermark': [],\n",
       "  'oracle_text': ['{T}: Untap target Gate.'],\n",
       "  'legend': [False]}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color_combinations = [[], ['W'], ['U'], ['B'], ['R'], ['G'], ['W', 'U'], ['W', 'B'], ['W', 'R'], ['W', 'G'], ['U', 'B'], ['U', 'R'], ['U', 'G'], ['B', 'R'], ['B', 'G'], ['R', 'G'], ['W', 'U', 'B'], ['W', 'U', 'R'], ['W', 'U', 'G'], ['W', 'B', 'R'], ['W', 'B', 'G'], ['W', 'R', 'G'], ['U', 'B', 'R'], ['U', 'B', 'G'], ['U', 'R', 'G'], ['B', 'R', 'G'], ['W', 'U', 'B', 'R'], ['W', 'U', 'B', 'G'], ['W', 'U', 'R', 'G'], ['W', 'B', 'R', 'G'], ['U', 'B', 'R', 'G'], ['W', 'U', 'B', 'R', 'G'], ['U', 'B', ''], ['G', 'W', 'R'], ['G', 'R', ''], ['G', 'W', ''], ['U', 'W', 'G'], ['B', 'G', 'R'], ['W', 'R', ''], ['R', 'U', ''], ['U', 'W', ''], ['', 'B', 'G'], ['B', 'W', 'U'], ['G', 'B', 'U'], ['W', '', 'R'], ['R', 'B', ''], ['', 'R', 'B'], ['R', 'B', 'W'], ['B', '', 'G'], ['G', 'R', 'W'], ['G', 'R', 'B'], ['', 'W', 'B'], ['G', 'U', 'W'], ['W', '', 'G'], ['U', 'W', 'B'], ['G', '', 'B'], ['G', 'U', 'W'], ['R', 'U', 'W'], ['G', 'W', ''], ['U', 'R', 'G'], ['G', 'B', 'W'], ['B', '', 'U'], ['W', 'U', ''], ['B', 'G', '']]\n",
    "\n",
    "decks = [select_cards(shortened_card_data, 20, {'color': c},\n",
    "                      exclusive = {'color': True}, blankparams = False,  \n",
    "                      negparams = {\"card_type\":[\"Land\", \"Token\", \"Emblem\"]}) for c in color_combinations]\n",
    "\n",
    "decks[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "852d303a-e6d6-47a7-b93d-a85188b99ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  0,  0, 20,  0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decklist = decks[5]\n",
    "total_lands = 20\n",
    "cost_ratios, minimums = deck_costs(decklist) #One normalised 1*23 array, and the minimums\n",
    "state = torch.tensor(np.concatenate((cost_ratios, np.asarray([total_lands*0.05]))), dtype=torch.float32).unsqueeze(0)\n",
    "# Sample action (land_ratios) from the policy\n",
    "# Convert probabilities to land_ratios\n",
    "land_ratios = land_policy_net(state).squeeze(0)\n",
    "land_ratios = torch.abs(land_ratios)\n",
    "\n",
    "# Perform any necessary normalization or conversion to integers, etc. here\n",
    "# Example: Normalize the values to sum to a specific total number of lands\n",
    "land_ratios = torch.mul(land_ratios, total_lands*0.2).requires_grad_()\n",
    "land_ratios = land_ratios.detach().numpy().astype(int)\n",
    "land_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4479f97-b83c-4ef2-9486-5a7950179318",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_lands(decklist, model = land_policy_net):\n",
    "    cost_ratios, minimums = deck_costs(decklist) #One normalised 1*23 array, and the minimums\n",
    "    #total_lands = sum(minimums)\n",
    "    state = torch.tensor(np.concatenate((cost_ratios, np.asarray([total_lands*0.05]))), dtype=torch.float32).unsqueeze(0)\n",
    "    # Sample action (land_ratios) from the policy\n",
    "    # Convert probabilities to land_ratios\n",
    "    land_ratios = policy_net(state).squeeze(0)\n",
    "    land_ratios = torch.abs(land_ratios)\n",
    "\n",
    "    # Perform any necessary normalization or conversion to integers, etc. here\n",
    "    # Example: Normalize the values to sum to a specific total number of lands\n",
    "    land_ratios = torch.mul(land_ratios, total_lands*0.2).requires_grad_()\n",
    "    land_ratios = soft_integer_round(land_ratios)\n",
    "    land_list = []\n",
    "    for c, v in ratios.items():\n",
    "        parameters = {\"set\": [], 'card_type': ['Basic'],'color': [c]}\n",
    "        exclusive={\"set\": False, 'card_type': False,'color': True}\n",
    "        blankparams={\"set\": True, 'card_type': True,'color': True}\n",
    "        if c == \"N\":\n",
    "            parameters[\"color\"] = []\n",
    "            blankparams[\"color\"] = False\n",
    "        if sets is not None:\n",
    "            parameters[\"set\"] = sets\n",
    "            exclusive[\"set\"] = True\n",
    "        land_list.append(i for i in select_cards(shortened_card_data, v, params = parameters, exclusive=exclusive, negparams=None, blankparams=blankparams))\n",
    "    return(land_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c8e3507-b767-413d-841a-cd2e488108f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def land_list_to_ratios(lands):#Turn a list of lands into a dict of color coverage\n",
    "    land_ratio = {\"W\":0, \"U\":0, \"B\":0,\"R\":0,\"G\":0,\"C\":0}\n",
    "    for land in lands:\n",
    "        for c in land[\"color\"]:\n",
    "            land_ratio[c] += 1\n",
    "        if len(land[\"color\"]) == 0:\n",
    "            land_ratio[\"C\"] += 1\n",
    "    return(land_ratio)\n",
    "\n",
    "def eval_card(card, land_ratio, total_l = None):#Determine the chance that a card can be played \"on curve\" using the given lands. Should be 100% for a mono coloured deck, less for rare colors\n",
    "    if type(land_ratio) == list:\n",
    "        land_ratio = land_list_to_ratios(land_ratio)\n",
    "    if total_l == None: #Doesn't have to be passed in, but it's quicker in case this is used many times at once\n",
    "        total_l = sum(v for v in land_ratio.values())\n",
    "    probability = 1\n",
    "    cmc = int(card[\"cmc\"][0])\n",
    "    if cmc > total_l:\n",
    "        probability = 0\n",
    "    else:\n",
    "        for color in [\"W\", \"U\", \"B\",\"R\",\"G\",\"C\"]:\n",
    "            num = card[\"mana_cost\"].count(color)\n",
    "            if num > 0:\n",
    "                if num > land_ratio[color]:\n",
    "                    probability = 0\n",
    "                else:\n",
    "                    hg = hypergeom.sf(num-1,total_l,land_ratio[color],cmc) #Chance you haven't gotten less than the required number of successes (ie lands of the right type). This can potentially be made more efficient if needed, but selecting different things to check in different cases, but this is probably fine in most cases\n",
    "                    probability *= hg\n",
    "    return(probability)\n",
    "\n",
    "def eval_deck(deck, land_ratio):#Iterate over all cards, written separately to clean up some other steps\n",
    "    if type(land_ratio) == list:\n",
    "        land_ratio = land_list_to_ratios(land_ratio)\n",
    "    total_l = sum(v for v in land_ratio.values())\n",
    "    probs = []\n",
    "    for card in deck:\n",
    "        probs.append(eval_card(card, land_ratio, total_l))\n",
    "    return(probs)\n",
    "def deck_costs(deck):\n",
    "    symbols = [\"W\", \"U\", \"B\",\"R\",\"G\",\"C\"]\n",
    "    ratios = np.zeros(len(symbols))\n",
    "    minimums = np.zeros(len(symbols))\n",
    "    fractions = np.zeros(len(symbols))\n",
    "    for i in range(len(symbols)):\n",
    "        c = symbols[i]\n",
    "        costs = [card[\"mana_cost\"].count(c) for card in deck]\n",
    "        devotions = [card[\"mana_cost\"].count(c)/max(card[\"cmc\"][0], 1) for card in deck]\n",
    "        ratios[i] = sum(costs)/len(deck)\n",
    "        fractions[i] = sum(devotions)/len(deck)\n",
    "        minimums[i] = max(costs)\n",
    "    #ratios = ratios/(max(np.sum(ratios),1))\n",
    "    costs = np.asarray([card[\"cmc\"][0] for card in deck])\n",
    "    colorscount = np.asarray([sum([min(card[\"mana_cost\"].count(c),0.2) for c in symbols]) for card in deck])\n",
    "    return(np.concatenate((ratios, minimums*0.2, fractions*2, [np.min(costs)*0.05], [np.max(costs)*0.05], [np.mean(costs)*0.05], [np.mean(colorscount)],[np.max(colorscount)])), minimums)#1*23 array of normalised values, and a separate mins array\n",
    "def refine_deck(deck, land_ratio, minimums={\"W\": 0, \"U\": 0, \"B\": 0, \"R\": 0, \"G\": 0, \"C\": 0}, target=20):\n",
    "    if type(land_ratio) == list:\n",
    "        land_ratio = land_list_to_ratios(land_ratio)\n",
    "    total_l = sum(v for v in land_ratio.values())\n",
    "    \n",
    "    # Find the worst-performing card\n",
    "    worst_card = None\n",
    "    worst_prob = 1.0\n",
    "    for card in deck:\n",
    "        prob = eval_card(card, land_ratio, total_l)\n",
    "        if prob < worst_prob:\n",
    "            worst_prob = prob\n",
    "            worst_card = card\n",
    "\n",
    "    if worst_card is None:\n",
    "        return land_ratio\n",
    "\n",
    "    # Calculate potential improvements\n",
    "    max_improvement = 0.0\n",
    "    best_change = None\n",
    "    for color in land_ratio.keys():\n",
    "        \n",
    "        # Adding a land of the required color\n",
    "        for delta in range(-2,2):\n",
    "            if abs(total_l+delta-target) <= 1 and land_ratio[color]+delta >= minimums[color]:#Try adjusting if it doesn't stray too far from the target or break the minimums\n",
    "                new_land_ratio = land_ratio.copy()\n",
    "                new_land_ratio[color] += 1\n",
    "                new_prob = eval_card(worst_card, new_land_ratio, total_l + delta)\n",
    "                improvement = new_prob - worst_prob\n",
    "                if improvement > max_improvement:\n",
    "                    max_improvement = improvement\n",
    "                    best_change = (color, delta)\n",
    "    # Apply the best change\n",
    "    if best_change is not None:\n",
    "        land_ratio[best_change[0]] += best_change[1]\n",
    "\n",
    "    return land_ratio\n",
    "\n",
    "def refine_deck_a(deck, land_ratio, minimums = {\"W\":0, \"U\":0, \"B\":0,\"R\":0,\"G\":0,\"C\":0}, target = 20):#Newest method of refining a deck's land list\n",
    "    if type(land_ratio) == list:\n",
    "        land_ratio = land_list_to_ratios(land_ratio)\n",
    "    total_l = sum(v for v in land_ratio.values())\n",
    "    oldeval = min(eval_deck(deck, land_ratio))\n",
    "    oldland = land_ratio\n",
    "    for color in minimums.keys():#Propose and evaluate a change per colour\n",
    "        if total_l <= target+1:\n",
    "            land_ratio[color] += 1\n",
    "            total_l += 1\n",
    "        elif land_ratio[color] > minimums[color] and total_l >= target-1:\n",
    "            land_ratio[color] -= 1\n",
    "            total_l -= 1\n",
    "        neweval = min(eval_deck(deck, land_ratio))#Reevaluate proposed change, note that this is time consuming\n",
    "        if neweval < oldeval: #Only accept changes that improve or don't change worst case performance of a deck\n",
    "            land_ratio[color] = oldland[color] \n",
    "    return(land_ratio)\n",
    "def refine_deck_old(deck, land_ratio, minimums = {\"W\":0, \"U\":0, \"B\":0,\"R\":0,\"G\":0,\"C\":0}, target = 20):#Previous refinement method, also didn't work well but was faster\n",
    "    if type(land_ratio) == list:\n",
    "        land_ratio = land_list_to_ratios(land_ratio)\n",
    "    total_l = sum(v for v in land_ratio.values())\n",
    "    for card in deck:\n",
    "        if random.random() < eval_card(card, land_ratio): #Make changes based on poorly performing cards only\n",
    "            cmc = int(card[\"cmc\"][0])\n",
    "            for color in minimums.keys():\n",
    "                num = card[\"mana_cost\"].count(color)\n",
    "                if num:\n",
    "                    if total_l <= target and random.random() > hypergeom.sf(num-1,total_l,land_ratio[color],cmc):\n",
    "                        land_ratio[color] += 1\n",
    "                        total_l += 1\n",
    "                elif land_ratio[color] > minimums[color] and total_l >= target:\n",
    "                    land_ratio[color] -= 1\n",
    "                    total_l -= 1\n",
    "    return(land_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c9764c6-4e2a-41d6-b64d-a632d13e5544",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'land_ratio_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mland_ratio_dict\u001b[49m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(filtered_land_ratio_dict)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(old_minimums)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'land_ratio_dict' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(land_ratio_dict)\n",
    "print(filtered_land_ratio_dict)\n",
    "print(old_minimums)\n",
    "print(eval_deck(old_deck, land_ratio_dict))\n",
    "print()\n",
    "print(eval_deck(old_deck, filtered_land_ratio_dict))\n",
    "deck_costs(old_deck)\n",
    "old_deck[-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5a031194-95a4-400c-b7a7-aa9f869098d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'W': 3, 'U': 3, 'B': 3, 'R': 3, 'G': 0, 'C': 3}\n",
      "19\n",
      "{'W': 4, 'U': 7, 'B': 2, 'R': 3, 'G': 0, 'C': 3}\n",
      "19\n",
      "{'W': 4, 'U': 7, 'B': 2, 'R': 3, 'G': 0, 'C': 3}\n",
      "19\n",
      "{'W': 5, 'U': 9, 'B': 0, 'R': 2, 'G': 0, 'C': 3}\n",
      "19\n",
      "{'W': 6, 'U': 10, 'B': 0, 'R': 1, 'G': 0, 'C': 2}\n",
      "19\n",
      "{'W': 6, 'U': 10, 'B': 0, 'R': 2, 'G': 0, 'C': 1}\n"
     ]
    }
   ],
   "source": [
    "print(land_list_to_ratios(landeck))\n",
    "land_ratio = refine_deck(newdeck, landeck)\n",
    "for _ in range(5):\n",
    "    land_ratio = refine_deck(newdeck, land_ratio)\n",
    "    total_l = sum(v for v in land_ratio.values())\n",
    "    print(total_l)\n",
    "    print(land_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "280efda9-675f-4beb-bcae-bec6d1b2dd98",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1263938695.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[6], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    ratios =  = {'W': 0, 'U': 0, 'B': 0, 'R': 0, 'G': 0, 'C': 0}\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def select_lands(n = 20, card_list = [], sets = None, offset = 0.4, test = False, iterations = 0):\n",
    "    #from cardutil import select_cards\n",
    "    ratios =  = {'W': 0, 'U': 0, 'B': 0, 'R': 0, 'G': 0, 'C': 0}\n",
    "    minimums = {'W': 0, 'U': 0, 'B': 0, 'R': 0, 'G': 0, 'C': 0}\n",
    "    total_c = 0\n",
    "    for c, v in ratios.items():\n",
    "        total_c += v #calculate inital total of colours\n",
    "    if test: #Optional rebalancing method\n",
    "        for c, v in ratios.items(): #reweight so that there's a more even spread of lands\n",
    "            if v > 0:\n",
    "                if v > total_c*0.9:\n",
    "                    ratios[c] = 3\n",
    "                elif v > total_c*0.5:\n",
    "                    ratios[c] = 2\n",
    "                else:\n",
    "                    ratios[c] = 1\n",
    "        total_c = 0\n",
    "        for c, v in ratios.items():\n",
    "            total_c += v #recalculate totals in weighted lists\n",
    "    if total_c == 0:\n",
    "        ratios = {\"W\":1, \"U\":3, \"B\":1,\"R\":0,\"G\":0,\"C\":0} #Default arrangement for colorless decks\n",
    "        total_c = 5\n",
    "    for c, v in ratios.items():\n",
    "        newval = max(v * n/total_c + offset,0)\n",
    "        newval = max(int(newval), minimums[c])\n",
    "        ratios[c] = newval#Currently just one step, weighted ratio will be used unless it's less than the minimum amount needed\n",
    "    \n",
    "    for _ in range(iterations): #Alternative fixing methods\n",
    "        ratios = refine_deck(card_list, ratios, minimums, target = n)\n",
    "    total_c = 0\n",
    "    for c, v in ratios.items():\n",
    "        total_c += v #recalculate totals in weighted lists\n",
    "        land_list = []\n",
    "    for c, v in ratios.items():\n",
    "        parameters = {\"set\": [], 'card_type': ['Basic'],'color': [c]}\n",
    "        exclusive={\"set\": False, 'card_type': False,'color': True}\n",
    "        blankparams={\"set\": True, 'card_type': True,'color': True}\n",
    "        if c == \"C\":\n",
    "            parameters[\"color\"] = []\n",
    "            blankparams[\"color\"] = False\n",
    "        if sets is not None:\n",
    "            parameters[\"set\"] = sets\n",
    "            exclusive[\"set\"] = True\n",
    "        sublist = select_cards(shortened_card_data, v, params = parameters, exclusive=exclusive, negparams=None, blankparams=blankparams)\n",
    "        for i in sublist:\n",
    "            land_list.append( i )\n",
    "    return(land_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7bb0771b-1f22-443c-8fc4-14a286d2bda1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "a = [3,6,8,1,1,2,0]\n",
    "print(sum(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "159e9dc9-f497-4eec-8c39-ad408903e13c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'select_lands' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m newdeck \u001b[38;5;241m=\u001b[39m select_cards(shortened_card_data, \u001b[38;5;241m20\u001b[39m, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolor\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mU\u001b[39m\u001b[38;5;124m\"\u001b[39m]},exclusive \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, blankparams \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, negparams \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolor\u001b[39m\u001b[38;5;124m\"\u001b[39m:[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mG\u001b[39m\u001b[38;5;124m\"\u001b[39m],\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcard_type\u001b[39m\u001b[38;5;124m\"\u001b[39m:[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBasic\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mToken\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmblem\u001b[39m\u001b[38;5;124m\"\u001b[39m]})\n\u001b[1;32m----> 2\u001b[0m landeck \u001b[38;5;241m=\u001b[39m \u001b[43mselect_lands\u001b[49m(\u001b[38;5;241m15\u001b[39m, newdeck, offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(newdeck))\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(landeck))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'select_lands' is not defined"
     ]
    }
   ],
   "source": [
    "newdeck = select_cards(shortened_card_data, 20, {'color': [\"U\"]},exclusive = False, blankparams = False, negparams = {\"color\":[\"G\"],\"card_type\":[\"Basic\", \"Token\", \"Emblem\"]})\n",
    "landeck = select_lands(15, newdeck, offset = 0)\n",
    "print(len(newdeck))\n",
    "print(len(landeck))\n",
    "print(land_list_to_ratios(landeck))\n",
    "carda = newdeck[1]\n",
    "print(carda[\"mana_cost\"])\n",
    "print(deck_costs(newdeck))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c46316-c5e8-4254-9abd-ea5a573fee1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(land_list_to_ratios(landeck))\n",
    "\n",
    "print(eval_card(carda,landeck))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff746298-eda7-4ec5-bd69-5afa887a6f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de305a73-ff2f-48c4-af22-fd73f7df9617",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "numlands = 20\n",
    "samples = 100\n",
    "maxiters = 7\n",
    "bestcase = 0\n",
    "bestcase_terms = []\n",
    "for offset in range (n):\n",
    "    for iters in range(maxiters+1):\n",
    "        for testcase in [True]:\n",
    "            start = time.time()\n",
    "            offs = offset/n\n",
    "            errors = 0\n",
    "            mins=[]\n",
    "            means = []\n",
    "            for _ in range(samples):\n",
    "                newdeck = select_cards(shortened_card_data, 20, {'color': random.sample([\"W\", \"U\",\"B\", \"R\",\"G\"],2)},exclusive = False, blankparams = False,  negparams = {\"card_type\":[\"Basic\", \"Token\", \"Emblem\"]})\n",
    "                landeck = select_lands(numlands, newdeck, offset = offs, iterations = iters, test = testcase)\n",
    "                errors += abs((len(landeck)-numlands)/samples)\n",
    "                probs = eval_deck(newdeck, landeck)\n",
    "                mins.append(min(probs)) \n",
    "                means.append(sum(probs)/len(probs))\n",
    "            pace = samples/(time.time() - start)\n",
    "            minprob = sum(mins)/samples\n",
    "            stdevmin = tstd(mins)\n",
    "            mean = sum(means)/samples\n",
    "            stdev = tstd(means)\n",
    "            print(f\"offset: {offs}, iters: {iters}\")\n",
    "            print(f\"avg card error: {errors}\" )\n",
    "            print(f\"min prob: {round(minprob,3)} +- {round(stdevmin,3)}\")\n",
    "            print(f\"mean prob:{round(mean,3)} +- {round(stdev,3)}\")\n",
    "            print(f\"pace: {pace}\")\n",
    "            print()\n",
    "            if minprob > bestcase:\n",
    "                bestcase = minprob\n",
    "                bestcase_terms = [f\"offset: {offs}, iters: {iters}\",f\"avg card error: {errors}\",f\"pace: {pace}\", stdev]\n",
    "print(bestcase_terms)\n",
    "print(bestcase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12efb62d-2898-4b1d-a303-c45a08d15cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def eval_deck_tensor(deck, land_ratio_dict_tensor, filtered_land_ratio_dict_tensor=None):\n",
    "    min_probs = []\n",
    "    card_probs = []\n",
    "    total_l = torch.sum(land_ratio_dict_tensor).clone().detach().requires_grad_(True)\n",
    "    for card in deck:\n",
    "        prob = eval_card_tensor(card, land_ratio_dict_tensor, total_l)\n",
    "        card_probs.append(prob)\n",
    "    min_probs.append(torch.min(torch.stack(card_probs)))\n",
    "    min_probs.append(torch.mean(torch.stack(card_probs)))\n",
    "    if filtered_land_ratio_dict_tensor is not None:\n",
    "        for land_ratio_dict_tensor in [filtered_land_ratio_dict_tensor]:\n",
    "            card_probs = []\n",
    "            total_l = torch.sum(land_ratio_dict_tensor).clone().detach().requires_grad_(True)\n",
    "            for card in deck:\n",
    "                prob = eval_card_tensor(card, land_ratio_dict_tensor, total_l)\n",
    "                card_probs.append(prob)\n",
    "            min_probs.append(torch.min(torch.stack(card_probs))*0.01)\n",
    "    loss = torch.sum(torch.stack(min_probs))\n",
    "    loss = torch.div(1,torch.add(loss,0.1))#loss = torch.pow(loss,4) #Steeper gradient around probability of 0\n",
    "    if filtered_land_ratio_dict_tensor is not None:\n",
    "        loss += torch.sum(torch.abs(torch.sub(land_ratio_dict_tensor,filtered_land_ratio_dict_tensor))*0.05)\n",
    "    return loss.requires_grad_(True), min_probs\n",
    "\n",
    "\n",
    "def combo (n, k):#Number of possible combinations, adjusted to allow continuous variables and to work with tensors\n",
    "    return ((n + 1).lgamma() - (k + 1).lgamma() - ((n - k) + 1).lgamma()).exp()\n",
    "def hypergeom_cdf(k, N, K, n):#Cumulative distribution function for draw likelihoods (likelihood of up to a certain value)\n",
    "    i = torch.arange(0, int(k + 1)).float()\n",
    "    num_comb = combo(K, i) * combo(N - K, n - i)\n",
    "    total = num_comb.sum()\n",
    "    return total / combo(N, n)\n",
    "\n",
    "def hypergeom_sf(k, N, K, n):#Survival function: odds of not getting k or fewer hits on n draws without replacement, given K targets in a pool of N\n",
    "    return 1 - hypergeom_cdf(k, N, K, n).requires_grad_(True)\n",
    "\n",
    "\n",
    "def eval_card_tensor(card, land_ratio_dict_tensor, total_l):\n",
    "    cmc = torch.tensor(float(card[\"cmc\"][0]), dtype=torch.float32)\n",
    "    probability = torch.tensor(1.0, dtype=torch.float32)\n",
    "\n",
    "    if cmc > total_l:\n",
    "        return torch.tensor(0.0, dtype=torch.float32)\n",
    "\n",
    "    for idx, color in enumerate([\"W\", \"U\", \"B\", \"R\", \"G\", \"C\"]):\n",
    "        num = torch.tensor(float(card[\"mana_cost\"].count(color)), dtype=torch.float32)\n",
    "        if num > 0: #If a card requires a certain type of mana\n",
    "            if num > land_ratio_dict_tensor[idx]:\n",
    "                return torch.tensor(0.0, dtype=torch.float32) #If there isn't enough of that type\n",
    "            else:\n",
    "                hg = hypergeom_sf(num - 1, total_l, land_ratio_dict_tensor[idx], cmc)#Probablity of getting enough of that type\n",
    "                probability *= hg#adjust overall probability\n",
    "\n",
    "    return probability\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "39b57779-2241-4676-b433-1c7b6b153877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scipy Implementation\t\tPyTorch Implementation\n",
      "----------------------------------------------------------------------\n",
      "0.333333\t\t\t0.333334\n",
      "0.455108\t\t\t0.455110\n",
      "0.439661\t\t\t0.439662\n",
      "0.495032\t\t\t0.495031\n",
      "0.620181\t\t\t0.620177\n",
      "nan\t\t\t0.629552\n",
      "0.708876\t\t\t0.708875\n",
      "tensor(5)\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import betainc as betainc_scipy\n",
    "\n",
    "def hypergeom_sf_scipy(k, N, K, n):\n",
    "    return hypergeom.sf(k, N, K, n)\n",
    "test_cases = [\n",
    "    (1, 10, 4, 3),\n",
    "    (2, 20, 8, 6),\n",
    "    (3, 30, 10, 10),\n",
    "    (4, 40, 15, 12),\n",
    "    (5, 50, 20, 15),\n",
    "    (5, 50, 20, 15.1),\n",
    "    (5, 50, 20, 16),\n",
    "]\n",
    "print(\"Scipy Implementation\\t\\tPyTorch Implementation\")\n",
    "print(\"----------------------------------------------------------------------\")\n",
    "for k, N, K, n in test_cases:\n",
    "    scipy_result = hypergeom_sf_scipy(k, N, K, n)\n",
    "    pytorch_result = hypergeom_sf(torch.tensor(k), torch.tensor(N), torch.tensor(K), torch.tensor(n)).item()\n",
    "    print(f\"{scipy_result:.6f}\\t\\t\\t{pytorch_result:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b58507e-c053-4228-97f5-122ae0c01544",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define a function to get all color combinations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a7fc59b-69b6-47bb-9f77-12f56c314a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[], ['W'], ['U'], ['B'], ['R'], ['G'], ['W', 'U'], ['W', 'B'], ['W', 'R'], ['W', 'G'], ['U', 'B'], ['U', 'R'], ['U', 'G'], ['B', 'R'], ['B', 'G'], ['R', 'G'], ['W', 'U', 'B'], ['W', 'U', 'R'], ['W', 'U', 'G'], ['W', 'B', 'R'], ['W', 'B', 'G'], ['W', 'R', 'G'], ['U', 'B', 'R'], ['U', 'B', 'G'], ['U', 'R', 'G'], ['B', 'R', 'G'], ['W', 'U', 'B', 'R'], ['W', 'U', 'B', 'G'], ['W', 'U', 'R', 'G'], ['W', 'B', 'R', 'G'], ['U', 'B', 'R', 'G'], ['W', 'U', 'B', 'R', 'G'], ['U', 'B', ''], ['G', 'W', 'R'], ['G', 'R', ''], ['G', 'W', ''], ['U', 'W', 'G'], ['B', 'G', 'R'], ['W', 'R', ''], ['R', 'U', ''], ['U', 'W', ''], ['', 'B', 'G'], ['B', 'W', 'U'], ['G', 'B', 'U'], ['W', '', 'R'], ['R', 'B', ''], ['', 'R', 'B'], ['R', 'B', 'W'], ['B', '', 'G'], ['G', 'R', 'W'], ['G', 'R', 'B'], ['', 'W', 'B'], ['G', 'U', 'W'], ['W', '', 'G'], ['U', 'W', 'B'], ['G', '', 'B'], ['G', 'U', 'W'], ['R', 'U', 'W'], ['G', 'W', ''], ['U', 'R', 'G'], ['G', 'B', 'W'], ['B', '', 'U'], ['W', 'U', ''], ['B', 'G', '']]\n",
      "Episode 0, Loss: 45.481075286865234, minprob: 0.0\n",
      "Episode 10, Loss: 21.7442626953125, minprob: 0.0\n",
      "Episode 20, Loss: 14.838000297546387, minprob: 0.09570829570293427\n",
      "Episode 30, Loss: 20.4289493560791, minprob: 0.024788260459899902\n",
      "Episode 40, Loss: 12.700048446655273, minprob: 0.04081175476312637\n",
      "Episode 50, Loss: 15.229973793029785, minprob: 0.0007486570393666625\n",
      "Episode 60, Loss: 13.902888298034668, minprob: 0.05107523500919342\n",
      "Episode 70, Loss: 14.147989273071289, minprob: 0.0\n",
      "Episode 80, Loss: 13.777626991271973, minprob: 0.0\n",
      "Episode 90, Loss: 8.167181015014648, minprob: 0.0\n",
      "Episode 100, Loss: 16.21196746826172, minprob: 0.0\n",
      "Episode 110, Loss: 14.901371002197266, minprob: 0.0\n",
      "Episode 120, Loss: 13.352686882019043, minprob: 0.0\n",
      "Episode 130, Loss: 24.50931167602539, minprob: 0.0\n",
      "Episode 140, Loss: 11.745664596557617, minprob: 0.21788257360458374\n",
      "Episode 150, Loss: 10.46895694732666, minprob: 0.14601916074752808\n",
      "Episode 160, Loss: 24.257328033447266, minprob: 0.0\n",
      "Episode 170, Loss: 13.556680679321289, minprob: 0.009040647186338902\n",
      "Episode 180, Loss: 12.520631790161133, minprob: 0.07636004686355591\n",
      "Episode 190, Loss: 12.378565788269043, minprob: 0.0638079047203064\n",
      "Episode 200, Loss: 16.949018478393555, minprob: 0.0003308485320303589\n",
      "Episode 210, Loss: 6.469692707061768, minprob: 0.024756789207458496\n",
      "Episode 220, Loss: 23.89496421813965, minprob: 0.00089856336126104\n",
      "Episode 230, Loss: 6.74235200881958, minprob: 0.1094745397567749\n",
      "Episode 240, Loss: 13.418599128723145, minprob: 0.0\n",
      "Episode 250, Loss: 11.86982250213623, minprob: 0.0\n",
      "Episode 260, Loss: 6.848861217498779, minprob: 0.0\n",
      "Episode 270, Loss: 17.864524841308594, minprob: 0.0\n",
      "Episode 280, Loss: 19.860551834106445, minprob: 0.0\n",
      "Episode 290, Loss: 15.112382888793945, minprob: 0.031469106674194336\n",
      "Episode 300, Loss: 21.900779724121094, minprob: 0.0\n",
      "Episode 310, Loss: 9.944520950317383, minprob: 0.07461881637573242\n",
      "Episode 320, Loss: 12.727038383483887, minprob: 0.005993843078613281\n",
      "Episode 330, Loss: 15.187146186828613, minprob: 0.006121993064880371\n",
      "Episode 340, Loss: 11.186735153198242, minprob: 0.03065163642168045\n",
      "Episode 350, Loss: 22.27309226989746, minprob: 0.0030649923719465733\n",
      "Episode 360, Loss: 16.302942276000977, minprob: 0.018393967300653458\n",
      "Episode 370, Loss: 15.791821479797363, minprob: 0.05018017068505287\n",
      "Episode 380, Loss: 14.702245712280273, minprob: 0.02358180284500122\n",
      "Episode 390, Loss: 15.549113273620605, minprob: 2.0384071831358597e-05\n",
      "Episode 400, Loss: 18.670421600341797, minprob: 0.0026893180329352617\n",
      "Episode 410, Loss: 8.487975120544434, minprob: 0.12324288487434387\n",
      "Episode 420, Loss: 8.934337615966797, minprob: 0.0407794713973999\n",
      "Episode 430, Loss: 9.740180969238281, minprob: 0.13499705493450165\n",
      "Episode 440, Loss: 9.68510627746582, minprob: 0.13804782927036285\n",
      "Episode 450, Loss: 12.370080947875977, minprob: 0.07527399063110352\n",
      "Episode 460, Loss: 10.086783409118652, minprob: 0.13805925846099854\n",
      "Episode 470, Loss: 8.543368339538574, minprob: 0.037285786122083664\n",
      "Episode 480, Loss: 12.0546875, minprob: 0.023724162951111794\n",
      "Episode 490, Loss: 25.646846771240234, minprob: 0.0\n",
      "Episode 500, Loss: 12.549111366271973, minprob: 1.1442345567047596e-05\n",
      "Episode 510, Loss: 11.948813438415527, minprob: 0.0\n",
      "Episode 520, Loss: 9.95755386352539, minprob: 0.04267227649688721\n",
      "Episode 530, Loss: 17.54275894165039, minprob: 0.02130349911749363\n",
      "Episode 540, Loss: 9.755435943603516, minprob: 0.1413777470588684\n",
      "Episode 550, Loss: 13.08860969543457, minprob: 0.0\n",
      "Episode 560, Loss: 9.151227951049805, minprob: 0.0009389510378241539\n",
      "Episode 570, Loss: 11.599870681762695, minprob: 0.08343803882598877\n",
      "Episode 580, Loss: 19.79113006591797, minprob: 0.0\n",
      "Episode 590, Loss: 14.285539627075195, minprob: 0.0\n",
      "Episode 600, Loss: 8.45217514038086, minprob: 0.0\n",
      "Episode 610, Loss: 12.684304237365723, minprob: 0.05256885290145874\n",
      "Episode 620, Loss: 6.122494697570801, minprob: 0.14310519397258759\n",
      "Episode 630, Loss: 8.244967460632324, minprob: 0.20330548286437988\n",
      "Episode 640, Loss: 13.429271697998047, minprob: 0.1241544783115387\n",
      "Episode 650, Loss: 11.431841850280762, minprob: 0.0005195189733058214\n",
      "Episode 660, Loss: 17.232982635498047, minprob: 0.0\n",
      "Episode 670, Loss: 13.409927368164062, minprob: 0.0\n",
      "Episode 680, Loss: 14.124711036682129, minprob: 0.032507047057151794\n",
      "Episode 690, Loss: 11.823369979858398, minprob: 0.11389408260583878\n",
      "Episode 700, Loss: 11.167847633361816, minprob: 0.023853003978729248\n",
      "Episode 710, Loss: 14.470961570739746, minprob: 0.02051236853003502\n",
      "Episode 720, Loss: 11.307557106018066, minprob: 0.15365955233573914\n",
      "Episode 730, Loss: 23.357303619384766, minprob: 0.0\n",
      "Episode 740, Loss: 11.783773422241211, minprob: 0.0612451434135437\n",
      "Episode 750, Loss: 9.992667198181152, minprob: 0.1296602338552475\n",
      "Episode 760, Loss: 18.16140365600586, minprob: 0.0\n",
      "Episode 770, Loss: 11.06159496307373, minprob: 0.0\n",
      "Episode 780, Loss: 11.371288299560547, minprob: 0.0\n",
      "Episode 790, Loss: 25.576602935791016, minprob: 0.0\n",
      "Episode 800, Loss: 10.840935707092285, minprob: 0.0\n",
      "Episode 810, Loss: 23.117631912231445, minprob: 1.5864802094256447e-07\n",
      "Episode 820, Loss: 14.384523391723633, minprob: 0.03024974837899208\n",
      "Episode 830, Loss: 11.0822172164917, minprob: 0.005342777818441391\n",
      "Episode 840, Loss: 21.59393882751465, minprob: 0.0004960031947121024\n",
      "Episode 850, Loss: 24.70218276977539, minprob: 3.916511559509672e-09\n",
      "Episode 860, Loss: 11.39423942565918, minprob: 0.023089420050382614\n",
      "Episode 870, Loss: 14.332066535949707, minprob: 0.029470140114426613\n",
      "Episode 880, Loss: 23.38902473449707, minprob: 2.128537346379744e-09\n",
      "Episode 890, Loss: 10.95663833618164, minprob: 0.13229797780513763\n",
      "Episode 900, Loss: 12.429502487182617, minprob: 0.09350389242172241\n",
      "Episode 910, Loss: 18.96595001220703, minprob: 8.688464731676504e-06\n",
      "Episode 920, Loss: 20.336469650268555, minprob: 0.0\n",
      "Episode 930, Loss: 9.400468826293945, minprob: 0.04582064971327782\n",
      "Episode 940, Loss: 16.009838104248047, minprob: 0.0\n",
      "Episode 950, Loss: 12.895105361938477, minprob: 0.0323968268930912\n",
      "Episode 960, Loss: 18.14328384399414, minprob: 1.3148930520401336e-05\n",
      "Episode 970, Loss: 12.767562866210938, minprob: 0.041900746524333954\n",
      "Episode 980, Loss: 13.819156646728516, minprob: 0.0004945738473907113\n",
      "Episode 990, Loss: 12.408592224121094, minprob: 0.13288375735282898\n",
      "Episode 0, Loss: 1.484135389328003, minprob: 0.07570953667163849\n",
      "tensor([0.0000, 0.2105, 0.0000, 0.0000, 0.6316, 0.0000])\n",
      "tensor([0.0000, 0.2000, 0.0000, 0.0000, 0.4000, 0.0000])\n",
      "tensor([0.0000, 0.1930, 0.0000, 0.0000, 0.4982, 0.0000])\n",
      "tensor([0.0500, 0.6000, 0.1737, 0.1368, 0.2000, 0.9500])\n",
      "tensor([4.0015, 3.9306, 3.9921, 3.5931, 3.9774, 0.0748],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor(1.3164, grad_fn=<AddBackward0>)\n",
      "Episode 100, Loss: 1.4756993055343628, minprob: 0.08149614930152893\n",
      "tensor([0.0000, 0.4000, 0.0000, 0.0000, 0.6500, 0.0000])\n",
      "tensor([0.0000, 0.4000, 0.0000, 0.0000, 0.4000, 0.0000])\n",
      "tensor([0.0000, 0.3533, 0.0000, 0.0000, 0.3536, 0.0000])\n",
      "tensor([0.0500, 0.3500, 0.1600, 0.1600, 0.2000, 1.0000])\n",
      "tensor([4.9835e+00, 5.1062e+00, 4.4530e+00, 3.7325e+00, 4.9857e+00, 4.4559e-03],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor(1.4013, grad_fn=<AddBackward0>)\n",
      "Episode 200, Loss: 1.2223559617996216, minprob: 0.17278100550174713\n",
      "tensor([0.0000, 0.8333, 0.0000, 0.0000, 0.0000, 0.0000])\n",
      "tensor([0.0000, 0.6000, 0.0000, 0.0000, 0.0000, 0.0000])\n",
      "tensor([0.0000, 0.6736, 0.0000, 0.0000, 0.0000, 0.0000])\n",
      "tensor([0.0000, 0.3500, 0.1667, 0.1250, 0.2000, 1.2000])\n",
      "tensor([ 2.8413, 11.8306,  1.5208,  3.7974,  4.8220,  0.0222],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor(0.7211, grad_fn=<AddBackward0>)\n",
      "Episode 300, Loss: 0.929051399230957, minprob: 0.34778469800949097\n",
      "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.7500, 0.0000])\n",
      "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.4000, 0.0000])\n",
      "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.4792, 0.0000])\n",
      "tensor([0.0500, 0.3000, 0.1594, 0.1375, 0.2000, 0.8000])\n",
      "tensor([ 0.7625,  0.7594,  1.3151,  0.9811, 12.0242,  0.0300],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor(0.4898, grad_fn=<AddBackward0>)\n",
      "Episode 400, Loss: 1.003868818283081, minprob: 0.29286760091781616\n",
      "tensor([0.0000, 0.6111, 0.0000, 0.6667, 0.0000, 0.0556])\n",
      "tensor([0.0000, 0.6000, 0.0000, 0.6000, 0.0000, 0.2000])\n",
      "tensor([0.0000, 0.3354, 0.0000, 0.6019, 0.0000, 0.0556])\n",
      "tensor([0.0500, 0.3500, 0.1722, 0.1778, 0.4000, 0.9000])\n",
      "tensor([ 0.0896, 10.0741,  0.0539, 12.0587,  0.4414,  0.0160],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor(1.3370, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_color_combinations(colors):\n",
    "    color_combinations = []\n",
    "    for length in range(len(colors) + 1):\n",
    "        for subset in itertools.combinations(colors, length):\n",
    "            color_combinations.append(list(subset))\n",
    "    return color_combinations\n",
    "\n",
    "\n",
    "# Get all color combinations, including the colorless deck\n",
    "colors = [\"W\", \"U\", \"B\", \"R\", \"G\"]\n",
    "color_combinations = get_color_combinations(colors)\n",
    "color_combinations+= [random.sample([\"W\", \"U\",\"B\", \"R\",\"G\", \"\"],3) for _ in range(32)]\n",
    "print(color_combinations)\n",
    "\n",
    "# Define the neural network architecture\n",
    "class ContinuousPolicyNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(ContinuousPolicyNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size*2)\n",
    "        self.fc2 = nn.Linear(hidden_size*2, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        # Initialize weights\n",
    "        init.normal_(self.fc1.weight, mean=0, std=0.25)\n",
    "        init.normal_(self.fc2.weight, mean=0, std=0.25)\n",
    "        init.normal_(self.fc3.weight, mean=0, std=0.25)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        #x = torch.mul(x,x1[0,0:6])\n",
    "        return x\n",
    "    \n",
    "    def print_weights(self):\n",
    "        print(\"fc1.weight\", torch.sum(self.fc1.weight).item())\n",
    "        print(\"fc1.bias\", torch.sum(self.fc1.bias).item())\n",
    "        print(\"fc2.weight\", torch.sum(self.fc2.weight).item())\n",
    "        print(\"fc2.bias\", torch.sum(self.fc2.bias).item())\n",
    "        print(\"fc3.weight\", torch.sum(self.fc3.weight).item())\n",
    "        print(\"fc3.bias\", torch.sum(self.fc3.bias).item())\n",
    "class ContinuousPolicyNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, hidden_layers=1):\n",
    "        super(ContinuousPolicyNetwork, self).__init__()\n",
    "        self.output_size = output_size\n",
    "        self.input_size = input_size\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(nn.Linear(input_size, hidden_size))\n",
    "        for _ in range(hidden_layers):\n",
    "            self.layers.append(nn.Linear(hidden_size, hidden_size))\n",
    "        self.layers.append(nn.Linear(hidden_size, output_size))\n",
    "\n",
    "        # Initialize weights\n",
    "        for layer in self.layers:\n",
    "            init.normal_(layer.weight, mean=0, std=0.25)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers[:-1]:\n",
    "            x = torch.relu(layer(x))\n",
    "        x = self.layers[-1](x)  # Remove activation function from the last layer\n",
    "        return x\n",
    "    \n",
    "    def print_weights(self):\n",
    "        for layer in self.layers:\n",
    "            print(\"weight\", torch.sum(layer.weight).item())\n",
    "            print(\"bias\", torch.sum(layer.bias).item())\n",
    "    \n",
    "    def add_preprocess(self):\n",
    "        new_layer = nn.Linear(self.input_size, self.input_size)\n",
    "        init.normal_(new_layer.weight, mean=0, std=0.1)\n",
    "        self.layers.insert(0, new_layer)\n",
    "    \n",
    "    def add_postprocess(self):\n",
    "        new_layer = nn.Linear(self.output_size, self.output_size)\n",
    "        init.normal_(new_layer.weight, mean=-0.2, std=0.1)\n",
    "        self.layers.append(new_layer)\n",
    "\n",
    "\n",
    "# Define hyperparameters\n",
    "input_size = 24  # cost_ratios and minimums concatenated\n",
    "hidden_size = 48\n",
    "output_size = 6  # number of possible actions (land_ratios)\n",
    "learning_rate = 1e-2\n",
    "num_episodes = 500\n",
    "deck_refresh = 1\n",
    "def soft_integer_round(x, factor=0.8):\n",
    "    return torch.add(x , (torch.sin((0.5+x) * 2 * math.pi) / (2 * math.pi)),alpha=factor)\n",
    "\n",
    "# Create the policy network\n",
    "policy_net = ContinuousPolicyNetwork(input_size, hidden_size, output_size, 2)\n",
    "optimizer = optim.Adam(policy_net.parameters(), lr=learning_rate)\n",
    "\n",
    "prelearning = 1000\n",
    "batch_size = 32\n",
    "episode = 0\n",
    "for episode in range(prelearning):#while prelearning and episode < num_episodes*batch_size:\n",
    "    if episode % deck_refresh == 0: #Keep decks for a short length of time, so that training can go towards something consistent for a while\n",
    "        total_lands = int(random.random()*20)+10 #Currently randomised, should this be fed into the model?\n",
    "        # Generate a random cost_ratio and minimums\n",
    "        newdeck = select_cards(shortened_card_data, total_lands, \n",
    "                     {'color': random.sample([\"W\", \"U\",\"B\", \"R\",\"G\", \"\"],3)},\n",
    "                     exclusive = False, blankparams = False,  negparams = {\"card_type\":[\"Land\", \"Token\", \"Emblem\"]})\n",
    "        cost_ratios, minimums = deck_costs(newdeck) #One normalised 1*23 array, and the minimums\n",
    "        #total_lands = sum(minimums)\n",
    "        state = torch.tensor(np.concatenate((cost_ratios, np.asarray([total_lands*0.05]))), dtype=torch.float32).unsqueeze(0)\n",
    "        \n",
    "    \n",
    "    # Sample action (land_ratios) from the policy\n",
    "    \n",
    "    # Convert probabilities to land_ratios\n",
    "    land_ratios = policy_net(state).requires_grad_().squeeze(0)\n",
    "    land_ratios = torch.abs(land_ratios).requires_grad_()\n",
    "    \n",
    "    # Perform any necessary normalization or conversion to integers, etc. here\n",
    "    # Example: Normalize the values to sum to a specific total number of lands\n",
    "    land_ratios = torch.mul(land_ratios, total_lands*0.2).requires_grad_()\n",
    "    land_ratios = soft_integer_round(land_ratios)\n",
    "    loss = torch.nn.functional.cross_entropy(land_ratios, torch.tensor(minimums, dtype=torch.float32))\n",
    "    loss = torch.add(loss, torch.pow(torch.sub(torch.div(torch.sum(land_ratios),total_lands),1),2), alpha=0.1)\n",
    "    #loss = torch.add(torch.nn.functional.cross_entropy(land_ratios, torch.tensor(cost_ratios[0:6], dtype=torch.float32)), loss) #Aim for something between the two\n",
    "    # Update the model's parameters\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if episode % (deck_refresh*10) ==0 :\n",
    "        filtered_land_ratios = torch.max(land_ratios, torch.tensor(minimums).requires_grad_())\n",
    "        _, minprob = eval_deck_tensor(newdeck, land_ratios, filtered_land_ratios)\n",
    "        print(f\"Episode {episode}, Loss: {loss.item()}, minprob: {minprob[0]}\")\n",
    "losses = []\n",
    "#policy_net.add_postprocess()\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-5  # You can adjust this value as needed\n",
    "optimizer = optim.Adam(policy_net.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    if episode % deck_refresh == 0: #Keep decks for a short length of time, so that training can go towards something consistent for a while\n",
    "        total_lands = int(random.random()*10)+15 #Currently randomised, should this be fed into the model?\n",
    "        # Generate random cost_ratios\n",
    "        color_combinations = get_color_combinations(colors)\n",
    "        color_combinations+= [random.choices([\"W\", \"U\",\"B\", \"R\",\"G\"],k=2) for _ in range(32)]\n",
    "        decks = [\n",
    "            select_cards(shortened_card_data, total_lands, \n",
    "                         {'color': c},\n",
    "                         exclusive = {'color': True}, blankparams = False,  negparams = {\"card_type\":[\"Land\", \"Token\", \"Emblem\"]}\n",
    "                        ) for c in color_combinations]\n",
    "        states = [# Sample state (land_ratios) from the policy\n",
    "            torch.tensor(np.concatenate((deck_costs(deck)[0], np.asarray([total_lands*0.05]))), dtype=torch.float32).unsqueeze(\n",
    "                0)\n",
    "            for deck in decks\n",
    "        ]\n",
    "        \n",
    "    \n",
    "    \n",
    "    batch_losses = []\n",
    "    batch_minprob = []\n",
    "    for state, deck in zip(states, decks):\n",
    "        # Sample action (land_ratios) from the policy\n",
    "        land_ratios = policy_net(state).requires_grad_().squeeze(0)\n",
    "        land_ratios = torch.abs(land_ratios)#.requires_grad_()\n",
    "\n",
    "        # Perform any necessary normalization or conversion to integers, etc. here\n",
    "        land_ratios = torch.mul(land_ratios, total_lands*0.2).requires_grad_()\n",
    "        land_ratios = soft_integer_round(land_ratios)\n",
    "        loss, minprob = eval_deck_tensor(deck, land_ratios)\n",
    "        loss = torch.add(loss, torch.pow(torch.sub(torch.div(torch.sum(land_ratios),total_lands),1),2), alpha=2)\n",
    "        batch_losses.append(loss)\n",
    "        batch_minprob.append(minprob[0])\n",
    "    \n",
    "    \n",
    "    # Update the model's parameters\n",
    "    avg_loss = torch.stack(batch_losses).mean()\n",
    "    optimizer.zero_grad()\n",
    "    avg_loss.backward()\n",
    "    optimizer.step()\n",
    "    losses.append(avg_loss.item())#.detach().numpy()[0])\n",
    "    if False and (episode+1) %100 == 0: #Readjust model periodically\n",
    "        policy_net.add_postprocess()\n",
    "        optimizer = optim.Adam(policy_net.parameters(), lr=learning_rate)\n",
    "    if 0 ==episode % (deck_refresh*100):#in ((episode+1) % (deck_refresh),episode % (deck_refresh)) :\n",
    "        print(f\"Episode {episode}, Loss: {avg_loss.item()}, minprob: {torch.stack(batch_minprob).mean()}\")\n",
    "        #policy_net.print_weights()\n",
    "        #print(land_ratios[0:-1])\n",
    "        #print(torch.tensor(minimums, dtype=torch.float32)[0:-1])\n",
    "        if 0 == episode % (deck_refresh) :\n",
    "            print(states[-1][0][0:6])\n",
    "            print(states[-1][0][6:12])\n",
    "            print(states[-1][0][12:18])\n",
    "            print(states[-1][0][18:24])\n",
    "            print(land_ratios)\n",
    "            print(loss)\n",
    "            for name, param in policy_net.named_parameters():\n",
    "                if False and param.grad is not None:\n",
    "                    print(name, param.grad.norm())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6edd96bb-4d26-4562-bb95-171a385207f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABcqklEQVR4nO3dd3zU9f0H8Nf3dhKSQBIgm4DsvWQIKIiKEdGqdQ/U0moV1FK1RmsdP1tsay1a3BYpatGqiHvgYMkykTBlJpAQEkIge1xyd9/fH8ldvnf3/d7KXW69no9HHubuvve9T77Eu1fenyWIoiiCiIiIKEhUwW4AERERRTeGESIiIgoqhhEiIiIKKoYRIiIiCiqGESIiIgoqhhEiIiIKKoYRIiIiCiqGESIiIgoqTbAb4AmLxYITJ04gPj4egiAEuzlERETkAVEUUV9fj/T0dKhUyvWPsAgjJ06cQFZWVrCbQURERD4oLS1FZmam4uNhEUbi4+MBtP8wCQkJQW4NEREReaKurg5ZWVm2z3ElYRFGrF0zCQkJDCNERERhxt0QCw5gJSIioqBiGCEiIqKgYhghIiKioGIYISIioqBiGCEiIqKgYhghIiKioGIYISIioqBiGCEiIqKgYhghIiKioGIYISIioqBiGCEiIqKgYhghIiKioGIY8cKWI6fx7o8lwW4GERFRRAmLXXu7U0ubGQatWvax61/bCgAYkpqAsVk9u7FVREREkYuVEYm3th7D0Ee/xBe7y10eV1bd3E0tIiIiinwMIxJ/XLMHAHDXf39yeZwgdEdriIiIogPDiAxRDHYLiIiIogfDiA9YGCEiIvIfDmAF0Ga24NufTwa7GURERFGJYQTAGz8U4y+f73d5jMXS2XfDMSNERET+w24aAF/tdV8VMXMgCRERUUAwjADQqNyXOswWaRhhaYSIiMhfGEYAaNXuL4N9GCEiIiJ/YRgBoFG7r3SYOGaEiIgoILwOIxs2bMC8efOQnp4OQRCwZs0at88xGo145JFH0K9fP+j1epx11llYvny5L+0NCI2KlREiIqJg8Xo2TWNjI8aMGYPbbrsNV111lUfPueaaa3Dy5En8+9//xsCBA1FZWQmTyeR1YwNF61FlxGL7XvRyMOu/NxVjf3kd/nrVaKg8GJ9CREQUTbwOI7m5ucjNzfX4+C+//BLr169HUVERkpKSAAA5OTnevmxAeTJmRJJFYLYoHyfn/z7dBwC4bGw6Zgzq7d2TiYiIIlzAx4x8/PHHmDhxIv72t78hIyMDgwcPxv3334/mZuXN5oxGI+rq6uy+AsndmJG6lja0tJltt32d5ttoNLs/iIiIKMoEfNGzoqIibNq0CQaDAR9++CGqqqpw11134cyZM4rjRpYsWYInnngi0E2zcTW193SDEROe+gZqyTEWjh8hIiLym4BXRiwWCwRBwNtvv41JkybhkksuwbPPPosVK1YoVkfy8vJQW1tr+yotLQ1oGzUy3TSiKOJ4dRM2Ha4CYD+AlYNZiYiI/CfglZG0tDRkZGQgMTHRdt+wYcPaP+yPH8egQYOcnqPX66HX6wPdNButTGWkf97nAIABKXFOjzGMEBER+U/AKyPTpk3DiRMn0NDQYLvv4MGDUKlUyMzMDPTLu1VZ34L/bDmm+HhRVaPTfVwanoiIyH+8DiMNDQ0oLCxEYWEhAKC4uBiFhYUoKSkB0N7Fcsstt9iOv+GGG5CcnIzbbrsN+/btw4YNG/DAAw/g9ttvR0xMjH9+ii548fsjXj/HbBFhMlvw+sYi7CmrDUCriIiIoofX3TT5+fmYNWuW7fbixYsBAPPnz8eKFStQXl5uCyYA0KNHD6xduxaLFi3CxIkTkZycjGuuuQZPPfWUH5rfddL1QzxlNFnw6Ed7sWp7+8959Om5/m4WERFR1PA6jMycOdPlol8rVqxwum/o0KFYu3atty/VLQQfNr2zrhtiJYoiHv5wD87qHYcFMwY4PUZERETKAj6ANdT5Y5+ZH49W26okzmGk6+cnIiKKZNwozw+aWpWXtudgVyIiIteiPoyo/FAakZ7DcUE0i8jdfomIiFyJ+jDiD9Iw0uqwcY10fCyLJERERM6iPoz4o1ohXTPNaLLgTx/twR1v5kMURbvKCBERETnjAFYfZtPInMSm1WTByo5F1A6ebEB6T0PnYeymISIichL1lRF/MJk7qx/NrZ0784oQ4cMyJkRERFEl6sOIiw17PSZdOK1RMrNGLQjspiEiInIj6sOIP7pO2iSVkUZjZxhRqezDiFwu+WTnCVz+wg84Xt3U9YYQERGFoagPI/4g7aapaWqzfa8WBId1RpzTyKJVO7CztAaPf7w3kE0kIiIKWVEfRgQ/lEak3TQLVubbvhdhXw0xW5SXh69vUV44jYiIKJJFfRiRVjV81aZwDovD1N63th7D+P9bi93HnXf6raw34t53dmBHSXWX20NERBROoj6MmCVVjYyeMbhmYqbX5zCZ5afMiKIIs2RF1i1Fp1Hd1IYHP9jldGxxVSM+KjyBK17c7PXrExERhbOoX2ekTRIWbpuWgwaj990lbRalyoj8oFUuN0JERNQp6isj0qqGKAIaH+b6GtvMsvebLfIrsGrVjCNERERWDCOSqoZFFHHOwBSvz2E0yXfTWBy6aaw06qi/7ERERDZR/6koHcBqEYHx2b3QN0GveHx2UqzTfS0KlRFRbD+nI7U/VlojIiKKEFEdRiwWER/vPGG7nZrYHkIm9ktSfE5SnM7pPleVEbmpvOymISIi6hTVYWTj4Srb9/EGDS4bk+H2Of1T4pzuU6qMmC2iw6Jn7dSqqL7sREREdqL6U9Ei6UN5YM4QW/dJvEF5ktHIjET0S7bvqlEKIxYRshvladlNQ0REZBPVYSRWp7Z9X1lntH2/+KLBshUQoH3tkN+ed5bdfUrdNKIoP5uGY0aIiIg6RXUYkc6kOVXfGUb6xBvw8cJpss+RW21VqTLyc3mdwtTeqL7sREREdqL6U7FNssbI7dP72z2mURjXYbZYnLa7+2rvSdljH/1or8LUXlZGiIiIrKI6jFiDwqA+PTAkNd7uMaUxpiaLKLuqqhKTTBhhNw0REVGnqA4j1i4XuQGrypUREaJTbUTZk5/sc7pP23Hu9QdPeXweIiKiSBXVYcTUMdVFbkVUpeLF0NQExfPJPWd3mfMOvWq1gLqWNsxfvt2zhhIREUWwqA4j1m4auUXIBMH5vr9cMQqXjEpV7KaJ1Xm276BKAI6fafa8oURERBEsqnfttXbTKHXJSPWJ1+OGydkAoNhJo9eo0GBUeFDira0leGtriafNJCIiimhRXRmx7tjryU69dgFEoTTSqrDeCBERESmL7jDS0U3jyVRbaf5QqowoLX5GREREyqI7jJiVB7A664wgSquztpoZRoiIiLwV3WHEWhnxct2P6QNT8H+/GIn37pyK8dk9bfdLl5fviv/9WIpL/7UR+yvqZHf9JSIiiiReh5ENGzZg3rx5SE9PhyAIWLNmjcvj161bB0EQnL7279/va5v9xpsBrNJMIAgCbp7SD2fnJNkt7X7fBYPswomvHvxgF/aU1eHipRvxf5/+3OXzERERhTKvw0hjYyPGjBmDZcuWefW8AwcOoLy83PY1aNAgb1/a78wd64zITe31lDSMpCbGYPVd06DX+K/gtPyHYr+di4iIKBR5PbU3NzcXubm5Xr9Qnz590LNnT6+fF0i2yogHYWRkRqLs/dIgY+3uYc8KERGR57ptzMi4ceOQlpaG2bNn4/vvv3d5rNFoRF1dnd1XINhWYFXopvnbL0cDAGK0ajxz9RjZY6SDX1UyC6URERGRawFf9CwtLQ2vvvoqJkyYAKPRiDfffBOzZ8/GunXrcO6558o+Z8mSJXjiiScC3TS3A1ivmZiFuaPSEKdXvkw6SRixVUa82LuGiIgo2gU8jAwZMgRDhgyx3Z46dSpKS0vxzDPPKIaRvLw8LF682Ha7rq4OWVlZfm+bydZNo1wgchVEAPtuGutuvDIb9RIREZGCoEztnTJlCg4dOqT4uF6vR0JCgt1XIFjXGenKAFZpkFHbxowwjRAREXkqKGFkx44dSEtLC8ZL27F206i9XGdESivbTeNfFpZaiIgognndTdPQ0IDDhw/bbhcXF6OwsBBJSUnIzs5GXl4eysrKsHLlSgDA0qVLkZOTgxEjRqC1tRVvvfUWPvjgA3zwwQf++yl8ZO2m0Xq0Aqs8aVVFFaDZNC+uO4x+yXGYNybdvycmIiIKAV6Hkfz8fMyaNct22zq2Y/78+VixYgXKy8tRUtK5I21rayvuv/9+lJWVISYmBiNGjMBnn32GSy65xA/N75o2i+cb5SmRq4z42zNfHwQAhhEiIopIXoeRmTNnuhwTsWLFCrvbDz74IB588EGvG9YdzH7optHIVEaIiIjIc1G9N03PGC3SEg1IMGh9Pofc1N5A4cBYIiKKRAGf2hvKnrh8JJ64fGSXzqHzcdEznUaFVpN3u/waTRaIIhDjpw35iIiIQkFUV0b8QRoMXC0rv/HBWXhgTud6KxqVgHd/M8Wr17ru1a0Y9qcv8dSn+/Dlngr86aM9qGtp877RREREIYRhpIvswoiLbpqspFgMSImz3VarBEwekIzfXzjY49cqLK0BALy+qRh3vlWAlVuO4a9fBH/3YyIioq5gGOmiGG1nGHHXTSMIzpvqddXhyga/nIeIiChYGEa6SBpGlDbcs5LO2lF3HOs4JPXuWWf5rW1EREThgGGkiwySbho3WQTSYohGYYG0YWkJuOPcAR6/PufXEBFRuGMY6SJvKiMqlfOmeo7MFhHgciVERBRFGEa6yG7MiJurqRY8DCPeYGmEiIjCHMNIFxm8qYzIDGAVHdLE2TlJDBhERBRVGEa6SLpRntrNbBppVpGrjGx8cBaykmK9yiKOYYaIiCjcMIx0kU7TeQkFhav5zeJzAdhXRuTCSFZSrNevv6esTvZ+URS5fDwREYUFhpEu6hWrs30vXRreKqWHHgP7xAOwDyDW1Vrl8oI3IaK5zYytRaednn/dq1txzStbGEiIiCjkRfXeNP4Qp9fg/TunQhAE2/gRg1aFljbnfWekxRC1u9GuXvh670lMGZBsu13T1IZtxWcAAJX1RvRNMPjttYiIiPyNlRE/mJiThAn9etluv/ObqbLH6dSdg121ftzh1+Ki+sFZwkREFOoYRgJgbFZP2/fSMa09Y7VO38vFCG97VlyFESIiolDHMNKNesV1ji+xdun0jtd3+byOWYTRhIiIwgnHjARYP8kMmTjJ0vHWTfOuOzsL+07UYvrA3rbHvA0TZoc0Il04jcGEiIhCHcNIgKy+6xz8e2Mx8i4ZartPumuv9TutWoUlV47u0ms5zpiRdtt4vaIrERFRN2M3TYCMz+6FF24cj8xe3q8d4u0QEOvxX+6pwIL//IjTDa22x+TGkzS3mnG0qtHrdhEREQUCKyPdbFhaAn4ur8MV4zP8dk5r9ePOtwoAAG3mzgBScKwa6Ykxdpv0XbR0PUrPNGPN3dPsBtsSEREFA8NIN/vfHVNwtKoJIzMSFI/xdon3T3adwLSBKbbbJ2qabd/f+04h6lpMuHlKP9t9pWfaH/9idznDCBERBR27abpZvEGLUZmJduNHHHnbTdPSZsF97xbabhtN9guuvbnlqPzrePcyREREAcEwEoGMJrPd7VaT82qwgHfLzhMREQUKw0gEcgwfymGkO1pDRETkGsNIBHLspmk1K4SR7mgMERGRGwwjEcgxjDjetmJlhIiIQgHDSAjq6lgOx4XOFLtpWBshIqIQwDASgkZkJPr1fIrdNMwiREQUArjOSAj65fhMtLSZMaFfL9z99k84erqpS+eTho5irrxKREQhhpWREKRSCbhlag5GpCfim8Xn4b4LBvnlvGU1zZj1zDrbbU7tJSKiUMAwEuI0ahXidP4pYO0srbG7zShCREShwOswsmHDBsybNw/p6ekQBAFr1qzx+Lk//PADNBoNxo4d6+3LRrVrJ2X55Twalf2qryyMEBFRKPA6jDQ2NmLMmDFYtmyZV8+rra3FLbfcgtmzZ3v7klEvwaDF3NFpXT6PVm3/z83ZNEREFAq8rv/n5uYiNzfX6xe64447cMMNN0CtVntVTaF2yjvZeE6jZmWEiIhCT7eMGXnjjTdw5MgRPPbYYx4dbzQaUVdXZ/dFXady2JyPWYSIiEJBwMPIoUOH8NBDD+Htt9+GRuNZIWbJkiVITEy0fWVl+WfMRDT7Zt9J3Pj6Nrv7WBkhIqJQENAwYjabccMNN+CJJ57A4MGDPX5eXl4eamtrbV+lpaUBbGV4EATXHTVD+sa7fHzBynyZe5lGiIgo+AK66Fl9fT3y8/OxY8cOLFy4EABgsVggiiI0Gg2+/vprnH/++U7P0+v10Ov1gWxaxOlh8P6fkpURIiIKBQENIwkJCdi9e7fdfS+++CK+++47vP/+++jfv38gXz6iuBvAqvJhhCvDCBERhQKvw0hDQwMOHz5su11cXIzCwkIkJSUhOzsbeXl5KCsrw8qVK6FSqTBy5Ei75/fp0wcGg8HpfuoawYf5NpzaS0REocDrMJKfn49Zs2bZbi9evBgAMH/+fKxYsQLl5eUoKSnxXwspYFgZISKiUOB1GJk5c6bLPU1WrFjh8vmPP/44Hn/8cW9fNuq5Gb/q00IkzCJERBQKuDdNhIjVqb1+DisjREQUChhGIsQlo9Jw7uDeXj2HY0aIiCgUMIxECJ1ahZW3T8ItU/t5/iRmESIiCgEMI2FCbkiI3HRendrzf1JmESIiCgUMI2HMca8ZANBpvAgjHDRCREQhgGEkTMgtBy8NI8PTEwAAeo33A1mJiIiCiWEkTOSOTAUApCUaOu8UgHX3z8Q7v5mCwR1703hVGfFrC4mIiHzDMBImLhzeF6vvOgdf3neu7T6VAOSkxGHKgGTbfVq15wuOsJeGiIhCQUD3piH/EQQB47N72d0nN2bk6OlGj8/JLEJERKGAlZEwJlcDuWp8psfPtw5gbWo14b53duDLPRV+ahkREZHnGEbC2MA+PZzuG5fdC4/NG+7R862VkRe+P4w1hSdw51sFfmwdERGRZxhGwtAnC6fjsjHpeOHG8bKP3zatP64cl+H+RB1p5HBlgx9bR0RE5B2OGQlDozIT8fz141we01c660aBdTn4umaTX9pFRETkC1ZGIlScBxvnmS0dYaSlLdDNISIiUsQwEqHi9O6LXmZL+38ZRoiIKJgYRiKUJ2HE0jGbpr6F3TRERBQ8DCMRKk5nH0ZGZyY6HWPtpjGZueIIEREFD8NIhOodr7e7HW9wrpSYLO39NJ6v2UpEROR/DCMR6uycXrhpSrbttk7t/E/darIoPr/BaELe6l344XBVQNpHRERkxTASoQRBwFO/GGW7rZEJI0YXYeRf3x3Cqu2luPH1bQFpHxERkRXDSJSQ20DP2KYcRkpONwWyOURERDYMI1FCrZKrjJjx/f5K1Bs7Z9NYOga1ckdfIiLqLgwjUUKrcq6MlFY347YVP9rd19YxqFV02NO3pc0cuMYREVFUYxiJEsk9dE73Waf2Slmn+UorI69uOIKhj36J7/dXBqx9REQUvRhGItwzV4/B9IEpWHj+II+Ol1tz5C+f7wcA3LbiR6zaXuLX9hERETGMRLhfTsjEWwsmIzFG69HxrWZrN428vNW7/dQyIiKidgwjUeTlmya4Pca6EBoHsBIRUXdhGIkiF49MtVsITU5nNw3TCBERdQ+GkSgjuFn8vc3svjKyp6wWC/6Tj0Mn6/3ZNCIiilLut3aliCIzw9eOybrOiItjrnjxB7SZRew9UYstebP91zgiIopKrIxEGUHwrDLi+pj2qFJe2+KXNhERUXRjZSTKuMki+LH4DJ7+Yj+KTjV2T4OIiCjqeV0Z2bBhA+bNm4f09HQIgoA1a9a4PH7Tpk2YNm0akpOTERMTg6FDh+Kf//ynr+2lLnI3ZuTxT/Zh46EqlNU0d1OLiIgo2nldGWlsbMSYMWNw22234aqrrnJ7fFxcHBYuXIjRo0cjLi4OmzZtwh133IG4uDj85je/8anR5Dt3lREiIqLu5nUYyc3NRW5ursfHjxs3DuPGjbPdzsnJwerVq7Fx40aGkSBwN4CViIiou3X7ANYdO3Zg8+bNOO+88xSPMRqNqKurs/si/3A3gNUbcsHmne0luOn1bahtbvPb6xARUWTrtjCSmZkJvV6PiRMn4u6778aCBQsUj12yZAkSExNtX1lZWd3VzIg3Prun386llkkjD63ejU2Hq/Cvbw/57XWIiCiydVsY2bhxI/Lz8/Hyyy9j6dKlWLVqleKxeXl5qK2ttX2VlpZ2VzMj3pwRqXjuurFIinPexddbrgbDHuCCaERE5KFum9rbv39/AMCoUaNw8uRJPP7447j++utlj9Xr9dDr9d3VtKgiCAIuH5uBd7aXYkvR6S6eS/mxyjpjl85NRETRIyiLnomiCKORH1bBpNV0/tMPSInDfRcM8vocRpMFL3x/GK2m9oXSTJIF00TubUNERB7yujLS0NCAw4cP224XFxejsLAQSUlJyM7ORl5eHsrKyrBy5UoAwAsvvIDs7GwMHToUQPu6I8888wwWLVrkpx+BfKFTd5Y17r1gEC4fm4F4gxb/9+k+r87z968OQK0ScOs5Oahp6hy02kPP9fSIiMgzXn9i5OfnY9asWbbbixcvBgDMnz8fK1asQHl5OUpKSmyPWywW5OXlobi4GBqNBmeddRaefvpp3HHHHX5oPvlKq1Y5fZ8Yo/XpXE9/sR9Pf7Hf7j4VFzQhIiIPeR1GZs6cCdHFlq4rVqywu71o0SJWQUKQXBgxaP3Xa2d2te0vERGRBDfKi1L2YaS9imHQqF0+54t7Z3h8fguzCBEReYhhJErpNJ3dKLqOYBKjcx1GvBkHYmEaISIiDzGMRCmdtDKicd9No1EJ0HvRjWORdNO0tJl9aCEREUULhpEoJT9mRLkyEqNVQ6vy/NfF3FEZefzjvRj66JfYU1brY0uJiCjSMYxEKek6I7YxIy7CiEGnhkbt+QwZa2FkxeajAIB/rj3ofSOJiCgqMIxEKWllxNplo9co/zrE6tR2z3HHcTYNZ/oSEZEShpEoJV30zBoyXIWNGK0aGrltehU4D2BlGiEiInkMI1EqTjIzxtpl42rRM4NWLbtLrxILKyNEROQhhpEoNSI90fa9dMzI5/fIryUSo1VD8CJROHXT+NBGIiKKDgwjUWpkRoLt+1hdZ5VkeHqC3OFu1yBxZLG4P4aIiAjwYTl4igyxOg3eu3MqmlvNHi1mFuNipo0cdtMQEZGnGEai2Nk5SR4f62rarxynMMKOGiIiUsBuGvJIjK79V8XT/WnMDt00rIwQEZEShhHyiHX2zZC+8R4d77izsyAARpMZ24pOo80xqRARUVRjGCGP9IrVAQBUKgHLbhjn9njn2TQCHvpgN659dSuWfL4/IG0kIqLwxDBCHpGuQaLXuB8/4rTomQB8uKMMALD8h2K/to2IiMIbwwgp0kmWh5eGEU/WPpPJIkRERLIYRkiRXrI8fIJBGkbcRwvH2TRERERKGEZIkTRz5KTE2r5XeVAaaWo14/x/rJOci7URIiKSx3VGSJEgCHj3N1NQ32JCZi9JGPEwVxSdauw8l78bR0REEYNhhBQJAjB5QLLT/Z5008idi4iISA67aUiRUujwJVgwixARkRKGEVKkFCDUPqSRsppmu9u7jtd43yAiIopIDCOkSClzeDKA1dGPR6vtbj/4/i5fmkRERBGIYYRckA8dPmQRIiIiRQwjpEipMsJpukRE5E8MI6RIqQLiy5gRRww0RERkxTBCigTFbho/hJEun4GIiCIFwwgpUu6mCdy5iYgo+jCMkKJA5gV/VFeIiCgyMIyQokCO62AWISIiK4YRUqQUGPyxIy+zCBERWXkdRjZs2IB58+YhPT0dgiBgzZo1Lo9fvXo1LrzwQvTu3RsJCQmYOnUqvvrqK1/bS91IqStFmkVevXmCbydnaYSIiDp4HUYaGxsxZswYLFu2zKPjN2zYgAsvvBCff/45CgoKMGvWLMybNw87duzwurHUvZTygrQuMmtoH9/O7dOziIgoEnm9a29ubi5yc3M9Pn7p0qV2t//yl7/go48+wieffIJx48Z5+/LUjZQCg7SbpitrjrS0mWHQqgEAHxQcxxd7KvDcdWMRp+dm0kRE0aTbx4xYLBbU19cjKSmpu1+avKQ0gFWUhBFf9qkBgMLSGgx99EtU1rcAAH7/3k588/NJvLaxyKfzERFR+Or2MPKPf/wDjY2NuOaaaxSPMRqNqKurs/ui7qdU9FCr/Pdr8+nOcrvbVQ1Gv52biIjCQ7eGkVWrVuHxxx/Hu+++iz59lMcaLFmyBImJibavrKysbmwlWSnVPEZnJGLmkN64aUq231/TZO76TB0iIgov3dY5/+677+JXv/oV3nvvPVxwwQUuj83Ly8PixYttt+vq6hhIgkCpm0alErDitkkBec02hhEioqjTLWFk1apVuP3227Fq1SrMnTvX7fF6vR56vb4bWkauBGPGi8liCcKrEhFRMHkdRhoaGnD48GHb7eLiYhQWFiIpKQnZ2dnIy8tDWVkZVq5cCaA9iNxyyy147rnnMGXKFFRUVAAAYmJikJiY6KcfgwIhGEuBsJuGiCj6eD1mJD8/H+PGjbNNy128eDHGjRuHP/3pTwCA8vJylJSU2I5/5ZVXYDKZcPfddyMtLc32de+99/rpR6BA6er+MWt/dy4Wzhro1XPazKyMEBFFG68rIzNnzrSb2uloxYoVdrfXrVvn7UtQmPvxkQtQ1WDEoL7xskvHpyYYUFHXIvtck4WVESKiaMO9aUiRrxvl9Y7XY1haAgBALlukJhps34sATkum87IyQkQUfRhGSJE/hoyIcE4jjuukXbbsB9v3HDNCRBR9uO42KfKlMOL4HIukNLL4wsEwmsw4UNFgd0xZTbPte86mISKKPqyMkCJfBrA6PkPaTXPP7EF4YM5QlyGnlZURIqKowzBCijzNIoP79lB8TG6ss6vTmlkZISKKOgwjpCgxRuvRca/fcrbiY3eeNwC94/X47cyzbPdJQ47jzCyOGSEiij4cM0JOXrhhPF7dWIS/XDHKo+Ozk2MVH+uTYMD2h2fbzcwRJLURs8N0G86mISKKPgwj5GTu6DTMHZ3m03PlpgO7miLsuK4I1xkhIoo+7KahbifNJo7dMm0m+8pIWU0z9pTVdkeziIgoSFgZoW4nDSOOA1YdKyPTnv4OALDpD7OQ2Uu5O4iIiMIXKyPkV55MwJGOGWnzsJtmZymrI0REkYphhPzKo+nAkmNeWnfE7iGlAax3//cnDm4lIopQDCPU7VzlFVdTe08qbK5HREThjWGEup2r2TWtLqofrSZWRoiIIhHDCHU71yuwijB1BBKLw/gRV0GFiIjCF8MI+ZXgwRBWd+NKjB0VEMfBrM2tZp/bRUREoYthhPzLgwGs7g6xhhHH1VmbGEaIiCISwwiFnFXbSzB1ybfYUVptdz/DCBFRZOKiZ9Tt+iYaXD7+968OAAAeeG+X3f1NraaAtYmIiIKHlRHqdgtnDcSUAUlujzM5rM7aaGRlhIgoEjGMkF/00LcX2cZm9nR7bLxBi3d+MxUZPWNcHmfQqu1uszJCRBSZ2E1DfrHm7ml4a+sx/HbmWR4/x+hm3RCDxjGMsDJCRBSJGEbILwb26YHHLxvh1XPcLe9u0NoX7hhGiIgiE7tpKGjcrai687j95njspiEiikwMIxQ03m58xwGsRESRiWGEgsZxhVV3mttYGSEiikQMIxQ0f7tqtFfHszJCRBSZGEYoaK45OwsLZw203X76ylEuj+feNEREkYlhhIIqpYfO9n2c3vXkrkYOYCUiikgMIxRUKlXntnmOi5w5cje195t9J3H5sk04XFmPTYeqUNvc5pc2EhFRYHGdEQoqQZCGEdfZ2N3U3gUr8wEAFzy7AQAwNDUeX953bhdbSEREgcbKCAWVWhJGYtxVRrwcwLq/ot6nNhERUfdiGKGgkvTSuO+maTNDFL2bDkxERKHP6zCyYcMGzJs3D+np6RAEAWvWrHF5fHl5OW644QYMGTIEKpUK9913n49NpUikEjwfM2K2iDjd2Ip/fXsIRacaPDo/Z+AQEYU+r8NIY2MjxowZg2XLlnl0vNFoRO/evfHII49gzJgxXjeQIptgVxlx/+v4yIe78Y+1B3Hxcxs9On9lfYuvTSMiom7i9QDW3Nxc5Obmenx8Tk4OnnvuOQDA8uXLvX05inBqST+NTuM+jHx/4BQA9/vaWLWZ2a1DRBTqQnI2jdFohNFotN2uq6sLYmsokKTdNHq1624awPMQYmXhGBMiopAXkgNYlyxZgsTERNtXVlZWsJtEASLtpvGkMuItEysjREQhLyTDSF5eHmpra21fpaWlwW4SBYi0MqJVCy6OlFdwrBpVDUbFx81ebsZHRETdLyS7afR6PfR6fbCbQd1AGkY0ahWGpsY7rQ9ywbA+qGpoRWFpjd39Px49g6tf3oJYnRr7nrxY9vxmN900hysb8PL6I6hpasVlYzNw2Zh0334QIiLyWUiGEYoejl0zn90zA//LL0Xe6t22+2J1GsTqnKfobjxUBcD1MvFmi+sxJte9ugVVDa0AgG9+rmQYISIKAq/DSENDAw4fPmy7XVxcjMLCQiQlJSE7Oxt5eXkoKyvDypUrbccUFhbannvq1CkUFhZCp9Nh+PDhXf8JKKydN7g3xmf3xIj0RADts2ukM2wAIFanRqzO+VdV78EYE3djRqxBhIiIgsfrMJKfn49Zs2bZbi9evBgAMH/+fKxYsQLl5eUoKSmxe864ceNs3xcUFOC///0v+vXrh6NHj/rYbIoUOo0Kq++aZnef47LwMTo1YnXOM2106s4w0maWr4C466YhIqLg8zqMzJw50+WS3CtWrHC6j0t4kzcuHpmKCf16oeBYNYD2wBKndw4j0gGvSjv0cgArEVHoC8nZNBTdtGoV3l4w2XZbJQiy3TRGyZojSmHEFAJhpNHoerdhIqJoxzBCIUk6HkQlQLabprmtc+CqUhixBDmMPP/tIYx47Ct8s+9kUNtBRBTKGEYoJAmSKb8C5Csj24rO2L73pDJyoKIev1rxI/aU1fqxpa49u/YgAOCPa/Z022sSEYUbhhEKeYJCZWRL0Wnb90q780rHjNz4+lZ8u78S17261f+NdIPL0hMRKWMYoZAnCIJsGJFSGpdxusGI7/afhMlssU3jbXAxhiNQg61DYOgKEVHI4qJnFPJidWrE6V3/qiotfPboR3sBAA9fMtSj17KIgA+r0rsVqTPKymubse7AKVwxLgMGrfuNDomI5LAyQiHrgTlDMDozETdOzkaMu8pIq+sZK5/tKre7LYoimmSeY3KzYquvIrWb5tLnNyFv9W78s2NsDBGRLxhGKGTdPWsgPl44HfEGLeJkBrBKNRmVl4QHYL89MIC73v4Jw//0ldNhXckiz31zCC98f1j2sUjtpjnd2N71tf7gqSC3hIjCGbtpKCzILXom5WociJwv9lTI3t9eGfG+u6GqwYh/ftNeHbhtWo7T7J9IrYxYCYJ831bpmSYYTRYM7NOjm1tEROGElREKC/F6rcvH3YUR6XY3jnvfSPm6Yqt0OXq5hdYiPItA7pKKoogZf/seFzy7XnHqNRERwDBCYaKHwXURr87Nh530s1LrYoSqryu2CpJXMMtszhfplRGVTGVEeikr61q6sTVEFG4YRigsuOumcfeXd01T5+NalfKvva8rtkrDhtymfaEYRpZvKsY1r2zxuotLjlxlRFplUujFISICwDBCYUKvcR1GqhqMLh8vqmq0fa8JQGXEJKmGtMqGEZ9OG1BPfroP24vP4K2tx7p+Mpm0Yd/lxTRCRMoYRigiVNR63g1Q3aRcRbF+gNa6OEaOdEqwSaabBiEYRqxa2tzMRPKAbGVEZGWEiDzDMEIRoVFh0TNvmSwi/vXtIYx58mt8UHDc4+dJqwBy3TTmEOymsdKqnd8GlJbXVyKXNaRjZ+TGlFi1miw4Xt3k1esRUWRhGCGSMFtE/KNjAa+81bs9fl6bWZT93ioUx4xYaRzKGh/vPIFhf/oSK34o9vgccmHD0wXkfvnyZkz/6/f+6S4iorDEMEJhI0ZmuXG1SkC8m5k23pBWOMSOvpXDlfXYdbzG4+fJVUZCLYu0mjrbqHGojNyzagcA4PFP9nl8PrkwIq0GuVoOf9fx9l2Uv9tf6fHrEVFkYRihsJHW0+B0X4xWjaQ4nd9eQ/rXvPXz84JnN+CyZT/gtItBsm2S58mFkVAjXQrf1VRnT8n1wkgDmtIAXukx3nYNEVHkYBihsJGdFOt0X684LXrGuF4QzRuuFj0rdzFI1r4yEmJlEBnSMTYWi6g4YPd7D6sVst00ZmkYkb8m0uDW7IeBtEQUnhhGKGw8Pm8EEmO0GJoab7tvVEYiEgIURkR4vtuu9EM1LCojkrVFXlx3BGOe/Bpvb3Mes3Hbih89Op9cZUQaQJTCiFHSXcTKCFH0YhihsJGTEocdj16I+y8aYrtvWGoCesb6r5vGsTLi6fLw7saMhJomyQd/ZX1799MjH+7x+XzyA1g7r4nSdZReq6a2ri++RkThiWGEwopKJdjtLROr1yAxxn8DWB0XPZPedLVWhsnNbBpvmS2ix1UZXzS2+veDX7YyIq0yKfwo0jBS18wwQhStGEYo7KgkYUSnFtAzxn+VEfsPUNGjKbktbWb8d3uJ7bavlZHy2masP3gKJrMFc5ZuwI2vb/PpPJ6Qdo94avfxWtz/3k7ZBebkdu19ZE1npUVxzIip8/76ljafl+MnovDmvz8pibqJWvLBp1Wr/Dq11+QwZkT6ISooLGn+yvoirN130nbb1zAydcl3AIDfXzgYhysbcLiyARaLaBe+/EVuMz935i3bBKB9tdu3Fky2e0yuiduLz3S+nkLIaDVLBtKKQEOrCQkG/40BIqLwwMoIhR3pPndatQoGmfVHfOXLmJGNh07Z3ZZdDt4LW4pO2763VjBa2sz48egZj8ewuOPpgmRyDlXWO93naoVVQHlqb6vJ/gF3uy8TUWRiGKGwo5GkEa1GBb3Gf7/GJodxDp6MGXGczSO3UZ43pK9jne76+sYiXP3yFvzqP57NbnHH1w0Blbgr3ngytRdwv/sy+W5HSTX+9NEeVNZ7vo8TUXdhGKGwI10wVKdWQa/136+xY+WhpqnV7vY720uw4D/5dtNQExy6iUwehJFDJ+sV1/aQDoC1bmK38VAVAGDdgVOyzzlQUY95/9qEL/dUuH3t9jZ6HkZWbS/BUcmux3LkxoxIKY0FcQxuHMQaOP/85hBWbjmGGX/9PqCDo4l8wTBCYUfaJaDTCNBr/NdN0+Qwy+S8v6+zu/3Q6t345ueTWLnlqO0NPUZn//rWMFF0qkH2NX4ur8OF/9yAyUu+kX3cbu2NjjDirivqt28XYHdZLe58qwAfFZa5PBbwrjKSt3o3Zj6zzna71WTB8k3FKJYEFHejWpRers3Eykh3KT3Tvhmh0WTBtz9z6X0KLQwjFHakU3u1av9205xpbFV8TNrV8OPRalz4zw34zcp8p8W6rH/tn/+P9bLn2XCwvbrR0iZfQTFKViK1Vkak3SAVtS246+0CuwGiVfWdS9Xf+06h4s9gdapeeWl7N0UOVDe14clP92GWJKC4HzPiYWWkhWEkUDJ7xdi+f2n9kSC2hMgZwwiFHZXgGEb8Vxk57SKMSD9Pv/n5JA5XNuDrfSednmO2iLIDTa1dFe6KEtLKyIGK9sGi0m6QB97fic93V+CaV7Z0ntuLqntlXQv++uV+z5/gAZWbdxJrGHHsHnBck4UDWANHGggLjlXLTtEmChaGEQo7GrVDGPFhzIhSNeVMg2eVEamDJ+1nl5gsouz0Xutmeu7WLpFWRhb/byfWHzxlVxkpOtXZPfKfzUc9OqfUD0eqPD7WU47Tnh3HiDS1mnHT69swdcl3qJaEt1aHbhp+QAaOY0D+Yk95kFpC5IxhhMKOdJ0RvY+zaZT2s3FVGVGaVnuyzr7Lw6IQRqyDRt0NHnRckGzVthK7yoh0Wu5jH+9tf00vwkggxi469tI4jkm5480CbDpchYq6Fqzc0rkHjuN1Kq1u8n/jCABg/bWZlJMEAHjmqwP4oOA4B7NSSPD6XXzDhg2YN28e0tPTIQgC1qxZ4/Y569evx4QJE2AwGDBgwAC8/PLLvrSVCID9CqxK3TSjMhJdnsNxBoxVdZNyGPF01dL2yojzG7zJLGJ/RR2e+fqgy+fLvY40gMnNhHFcNuR/+aW4Z9UOp8oD4D6M+LLEmuOYEVfroUiDk+OYka/2nsSWI6cdn0J+YO647tdNykJqggGNrWb8/r2deHOr8waJRN3N6zDS2NiIMWPGYNmyZR4dX1xcjEsuuQQzZszAjh078PDDD+Oee+7BBx984HVjiQDHFVgFu8rILVP7oXjJJfjDxUNdnkOpMiL34W3lONNGiUUUZaf3tlksuO0N9+uENBidX0f6WS9XdXGsjDz4/i58vPME3vmxxOnYQHCujChfR7sw0nG9h/Tt3In5luXb7GbqkH9Yr3sPvQbv3TkVFw7vCwD413eHbQOliYLF6zCSm5uLp556CldeeaVHx7/88svIzs7G0qVLMWzYMCxYsAC33347nnnmGa8bSwTIzKaRjBkxaNUQBAFateu/7xMVwoirpdwbjZ69YZvMouzCZyaziHIfx0RIKw1y03LNCuWOJz7Zh+Wbiu3u646ivKsFXqVhxBraBvbpgd9fOBhA+6DWT3aeCGj7opF1HI9aJSArKRYv3DAeGT1jcKreiNc3FgW5dRTtAj5mZMuWLbjooovs7pszZw7y8/PR1iY/ct5oNKKurs7ui8hKGkZ0GvtuGmvI0Khd/2or7X/iav2NRz/ao/gYAEwZ0N4X314ZcT5Pm9nidqVSJfYf4M7nVup6MVtEPPnpPrsps96ML/G8ffa3XVVGpDnNJPmAXDR7EP521WgAwNf7PFu8jTxnDazWbk6dRoXFHQHwma8P4nfvFrqsDBIFUsDDSEVFBfr27Wt3X9++fWEymVBVJT+qf8mSJUhMTLR9ZWVlBbqZFEakXQJatQo6STdNdlJsx/3On/rnD+1j+15pcz1Xq6fWKKyYatU3wdB+DotFfjaN2YKkOOcdhlvazMg/esbpfin7yoj3Hxhf7PZ85oS71VTlWAPO6xuL8J/NR12OGZEOmLQep+n4gJw9rA9UArCnrA5/XLMbN7y2FXvKam3Hch0S31l/JaXdnFeOz8CvpveHIAAf7ijDlS/9gMXvFqKspjlIraRo1S279jq+uVnfjJTe9PLy8rB48WLb7bq6OgYSspF+0OkcZtPkJMcBsN+/xuovV4zClCXfAgBidfJrk8gNPPWUoaNCY7bIn8dkERGr0wDoHCQriiJ+924hvnCzjLv0s92XbWX+8MFuXHt2dkf7/F8ZEUURVQ1GPPXZzwCA8wb3VjxWWpmx/rVurXYl99BjYr8kbD96Bm9tbR/vcum/NkGvUcFoskCrFnDFuAwcqmyAQaPGyzdNQGIsd/n1hLSbxkoQBDx66XBM6p+EO94swJ6yOuwpq0Px6Ua8+5updkGfKJAC/puWmpqKigr7N9rKykpoNBokJyfLPkev1yMhIcHui8hKWhjQqARo1SpcPykLc0enYUR6+++KXGVEuj6J0kJpXdnN1rosvNlFZcQxf5stotsgIgj+7VoJRCnebBHtVqJ1NfZGmoXMZucPyLmj05yeY51h1GYW8b/849hRUoMtRacx/W/f4d53diguvU+dbN00Mn8EzhmRihdvHI8Zg1IAADtKajD4j1/g+le3cnArdYuAV0amTp2KTz75xO6+r7/+GhMnToRWy79oyHvpPQ3I6BkDvbazKrLkytF2x8iNGZGOE3Es9984ORtvbyvxagM5R9aBtGZLZ6jplxwLk1lEWU0zTGbRadqsp3vE+KOaYbGIUKkEuzCiVQtdqgbZzi3aj1txtXOxq8oIANwwORsnapvR0mrGgxcPxfajZ/D9/kqYLCJaWs34sLAMOnV7paS+xYSPCk9gW9EZ3DYtBwN698BZvePw2a5yqFQCthefwfD0BPRPiUMPvQYGrQpFpxpxdk4ScpLjoNUIaGgxoU9HF1skk6uMSF0yKg2XjErDs2sP4vlvDwEAthSdxtBHv4RGJSAnJQ7PXTcWA1J6OO3HRNRVXoeRhoYGHD582Ha7uLgYhYWFSEpKQnZ2NvLy8lBWVoaVK1cCAO68804sW7YMixcvxq9//Wts2bIF//73v7Fq1Sr//RQUVTRqFdY9MBMqQVDs6pOrjOg0Kvz9l6Ox9JtDuHpClt3iW7dP74+3t5W4/IvenRhtZ2Wk1SR2tEMFwPpXvcXpg9/TkOGPMNJqtsCgUtsFBa1ahTaz/V++voyxFUURomSejquAI12d1SzzAalVq5CXO8x2e9aQPpg1pHO8z5+vGIUYnRprdpThza3H2pc2r2vBki/kl7hff1B+p2NHUwYkYVx2L2w8dApNRjN6xenQM0aLncdrcOHwvth0uAqLzh+EOSNSkWDQ+DS2JpgstuDn+rh7Zw9CTnIsthWdwbv5pQDaQ/PhygbMfX4TYrRq/PmKkdCoVcgdmdrxO07UNV6Hkfz8fMyaNct22zq2Y/78+VixYgXKy8tRUtK5tkH//v3x+eef43e/+x1eeOEFpKen4/nnn8dVV13lh+ZTtHL3Bqj0+NUTs3D1ROfxR9YBlHUtvm9hb91Z1ywCP3YMSG0/b3tblv9Q7DQw0NPKiD+6aYwmCwxatd2iahpfp/c4cKqMuOgKkv7IJjd/rcux/lX+i3EZ+MW4DJxpbMXrG4tQXNWIbcVncKaxFX3i9dCqVUjpoUNRVSOMJovb7qmtRWewtUgykFiy1smq7e0fyg++vwsPvr8Ls4b0xhu3TfK4zaHA7GasnpVaJeDK8Zm4cnwmrp2UhYKj1Sg8XoPPdrUPgm5uM2Px/3YCAEZnJuLysRm4eGQqMnrGoM1sYTghn3gdRmbOnOly+eAVK1Y43Xfeeefhp59+8valiHzm7Yesu6nASib1T7LtnmvQWLtpLHh2bfsqq/sr6jE0tX1Br893O48NcdzDRc4Xeypcrihb42LVWCmjyQxAa/eh7K8BihZRtFu/xNUH/5tbj+FP84ZDq1bZfv6uhKKkOB0e7Fjkrs3c3nUjnbVkNJkhiu2vUd9iQrxBgwajCaLYvvz89uIz2Fp0Gj1jdahvacORU41oaDGhok55TZjvD5zC8k3FuH16f5/b3d0sMrNp3Bmf3Qvjs3sBAC4bU4Gv9lRg9Y4y2+O7jtdi1/FaPP3Fz+gTb0BZTTMm9uuFjF4xUKsElNe0YExWT1w6Og2D+vbw66aWFFm6ZTYNUSgShM6/5rU+fhhK39itgabeobri6i9FTysjuzumt8oZ++Raj85hbGv/NGoPJe7b5g2LaN+V5K67a+OhUzh/aF/bz6/yU4VGq1Y5TZ+WfgD26nisZ6zOdnt0Zk8smDHA6VynG4xYd+AURmUm4v2C4xiRnoCv9520VQje3nYsrMKIXJeYN+aMSMWcEalYNHsQNh46hTaziK1Fp1Fc1YjDlQ22ql/+sWrkH6u2PW9L0Wm8vP4IcpJjMX1QCib3T8agvj0wNNV5YkJtUxtEiNCqVTjT2IrURAME+P7HAoUPhhGKSO1TaF0T0Lkaqa9vdtIZOta/7h2XMte4WA32+/2VPr2uL779+SQm5iTZd9M4tO2nkmqnGT+eEEXRLoy428enubX9ccd1RkJJcg89rpqQCQB4+JL2MSyXj83AH+Y04dy/f4/S6mbboOBw4Go2jTf6p8Shf0r7FPpfdYSxgyfrse9EHVrazHh1QxH6JceiX3Ic6lraUHCsGsdON+Ho6SYcPV1im7Idr9dAq1GhzWTB4NR4WEQRByrq0dxmtuvyG5ASh69/dy4DSYRjGKGIFKNT4+0Fk/Hy+iPYeEh+cT0pV4HBFekbu/VD6Xi1/bgQrcyaJ1YPfrDLp9f1xeOf7HO6z7EycuWLm90upS9n46Eq3PlWge22q9k07Y+3V2dsf62H0WDQ9J4GqDtmJZ1qMNoWuwt17mbTdMXgvvEY3LG/0HWTsp0er29pw8c7T2DfiToUltbgQEU96o0moGPD6wJJJcVRUVUj6hy63ijyMIxQxJo2MAU7j9cohhFB0k/jKjA4UgmdgzClb+xKf92H8sJROj/+tSmtCLkbLGp9vHMAa+heI0catQoZPWNQcqYJJWeawiaMmD2cTRMI8QYtbpzcz3a7qdWE49XNOFVvhEUUcfR0ExIMGhi0agzpG4+qBiOqm9rw65X5AFyvjEyRgWGEIpqrv7iljzhWRs7qHYcjp+R3jk2M0aK6Y2l4aWVE6S/OHvrO/80G9emBQ5Whs0BXoGY+uBszcqCiAcs3Fdt2Qva1MhUsWUkdYeR0E87OSQp2czxirYx0tZvGH2J1GrtqyoxB9o/ndHQD6dQqtJotHo+tovAVPn+OEPnguknZ6Jcci1/PcB5oKH1PllY1rp+UhRmDlJczl4YO6We5UhiR7oPzi3EZ+Pb357lt94j0BCycNdDtcV1118yzAnJed5WR5T8U48lP9+GjwvbdeUPhA9Ib1j2QSs40BbklnrN+nofTtbaG1EBsYUChhZURimiJMVqsu3+m7NoKgmQIq+BQ4VB6vz53cG/slcxske6Bo1SFiZes/BqjVeOs3j3ctlujVuH+OUPwc3kdvg3QINffXzgYsySbB1r5469QbxePC8UBrK5kdYSR0urwCSNdnU0TDNa2dmUxQgoPrIxQxPN2pUyNStURVJw988vRdguQqVSuu2k+XjgNPSSVEU+X0dZ1/EVoXUjNs+eoMGdEX/cHdkjvGQODVo1rJmba3e+PbXDcDWB1FC4zUqyyenWEkTCqjNhm04TRtbZ2I7IyEvkYRih6Kbwna9XKlRGdRmW3gqh0qINjGLn1nByMzuyJBGkY8TBcWCsu3sxsaTVbkBSn9/h4awn8/ouG2N1v0Hb9bcHbzfjCrTISlt00YThzyfr/FMeMRD6GEYpaSm/JGrVK8TGtWmVXGRmR3rkyqmMYsW6cJx3A6mmlwxoUvB1gqvdi5o713I7t9segVm/DSDh1HQCdYeRknRHf7DuJuc9vxMMf7g7pHW47KyNBbogXrCG1KxtYUnjgmBGKWkp/IGpVAkwuKiN3nncW/v7VAVw6Og23TstBU6sZ5w3pjXqHnYD1HR/qdmNGPOymsQYCb6cFe/Ohbn2j1zh8OnkbJOREehjpGatFvF6DeqMJCzqmn+49UYcNB0/h1nNycPWELCTGhs6u5KIo2rrfwqkyYg3l1l2wKXIxjBA50KhVEBQ+TDUqAb897yxMH5iCYWkJ0KpVuPeC9nmJm4/Yr2ei76iCWFerBICsXjEetcH6ceFtlcKbD3VbZcShK8jd6qmecFwS351wCyOCIGB4egK2FZ+xu/94dTOe+uxnvF9wHB8tnBYye7HYdS2G0bW2BmV200Q+hhGKWkqDVPUaFRqNCs8R2seTjMnq6fSY41+c1i6T4ekJ+HTRdKhVAgZ4MJMG6Fym3tvKiDd/9Fr/6gzEeI3TShdQQTj9tW41NqunLYz84eKh0GtU+Gx3OXaUVGN/RT1e+P4IzjkrGSPSE+yqY8EgHQDq7YDuYFKzmyZqhFHvIZF/Ob4nL5jeH/2SY9uXs/bh/dpx4S5pkBiZkYhhac4bgymx7ozt7Qqp3nyoWysjgVh34lSDZzsJW4XbomcAsGDGAJyd0wszh/TGbdNycPv0/vjgt+fg2WvGAgCe//YQrnt1Kxb/b2dwGwrYjXMKr8oI1xmJFqyMUNRy/BD+46XD8cjcYe3VDx/SiOP5vBlM6sgaZLzpphmX3dOrYKENZGWkQbkyIt0t2SqcPiCtesfr8d6d5zjdf/nYdPx3ewm2d1RNvvn5JMprm5GW6FkXXSBIP8zDqQplDaltYTRmRBRFHDhZj4G9e3BzPy/wSlHUkntLtpawfXm/dppN04XxAtYpulqN/Tn/cPFQxee8+avJ8OYz3dofL7fuhC+b5Umd7qiMpCc679tinYkiFU4fkO4IgoDXbp6Il24cjwEpcRBF4NblP+Ltbcewv6IOr6w/grzVu3G4G7cFMNutjdNtL9tl1j2LzGHUTfPtz5W4eOlGXPXyFluFk9wLo19Lou7jy0ej4yA7V+M9bj0nx+W5kjt2KHXsprl0dJrs8Qeeuhg99BqnYHHj5GycO1h+aXtXXSOGLg68bO6Y4vropcOdHhvUx3ncTDhWRlxJjNUid1Qarjk7CwBw4GQ9HvlwDy5euhFLvtiPVdtLcOm/NuLZtQex90Stm7N1nSVMKyPaMFxnZH9FHQBgZ2kN9lfUB7k14YNhhKKXi/dkX8ZRtLTarzHharzHbdNyXJ7Lul26Y6CR+9DWqARbFcax3X++YhSGpsbLvoarLiCDh1OQ3UmMcR64md7Tubsi0sKI1fypObh0dBrGZPVE3wQ9DFoVhqbGIzlOh5Y2C57/9hCueHEzvt5bgf0VddhWdNovU6sd2XXThNG17lz0LHy6aaT/z/5wWH7HcHLGMSMUtVy9Jfvyx6PeYeXS3vHKq6G6CztTz0oG4BwY1CoBb9x6Nm5b8aPsuaQfNBsemAVAeUyIq7Einq7CeuHwvvjhcBWaWuUX+5IuhW8lF9LC6QPSGzE6NZbdMB5A56BkQRBQWdeCX6/Mx87jtWg1WfCbNwtsz8lOisUlo9LQ3GrCuOxe+MW4jC63w5pFBCG8ZtOE40Z50irO3hN1QWxJeGEYoajl6k3Zl7fr8dm9kBijRW1z++JnZ8l0R1g5dpFM6p+E26f1R6xODYNWbZt5E+tQoRAEYNbQPjj69FzkPPSZ7T7p41bZybEdryUfLFxVRjxdtn5YWgL+df04/HHNHrxfcNzpcenqs1Zy3VeOC69FIunvW58EAz5aOB21zW1Y+N+fsOXIacQbNKhpbkPJmSa8vP4IAOA/W47h450n0DNGi4tG9MV5g/ugtrkNMTq1bNVJiXU2TTjt2AtI1hkJozEj0vEtR05137igcMcwQlGrT7zeFhyc+PCmLQgC/jh3GB54fxcA+Q9iK8d++5QeOlw8MtXpuFid/Tnk+vvtKiMyjytWRlyMGVEKI3E6NRolVZC0RAMMWjVMChvjyVVG5EJQFGQRWYkxWrz5q8kQRRGCIKDRaMLyTcVYufUYWlrNqDea8F3Hrs2rd5TZnhdv0ODRS4dDLQjIHZXq9HviyByG+9IAkuXgw6ibRjpY+Ehlg+3fllxjGKGo9dJN45G3ejfunT3Y6TFf3zrmjUnH1/tOYtaQPi6PcxxomtJDvksnzqEyItedIb1LdkyJQuhwVY3QK4SRK8dn4s2tx2y3rT+n0gDDeL3zX+/RWhlxxfphFafXYNHsQVg0exDMFhHPrj2A3WV1iNWqsaXotC0817eY8GBH6H34w90YmhqP4ekJuGvmQKT00CNGp8apeiNKzjRhTGaiLYyE22UOx43ypF1Kja1mVNS1BHVad7hgGKGoNbBPvOw6EYB9YUSvUXm8RLpBq8Zrt0x0e5zjX6gXDOsre1ysQ3VFbhqutDIiV4ZXqoy4mr6rVBmZMSgFl49NR+94PfQaNVI7pu4qldHlxp7IjxlRbErUUqsEPDCncyq32SJiW9FpAMBDq3fbdgw2mizYebwWO4/XYtX2UqiE9qpcXceS/H3i9bZqVEtb+FQYgM4qWriOGQGAI5WNDCMeYBghkpEmWR8jEEsFSEOFXqPC9IEpssc5VkbkPsil+UMud0irDhP69ULBser2+13NplEYwKpRC5iYk+R0v9JfrnLlabkQpA63P9mDQK0ScE7H78kni6bjcGU9YnUa/P2rAzhR04yTdS2obmqDRYQtiABAZb13S/OHEmtlpC2MxoxYHP5f2Hm8BtMGJrOrxg2GESIZV43PxL4TdZh6VjLuevsnv59f2p0yMiNRtuIBtJftrQakxMEgqVgkx+lwurHVNvMGkO9ekX74D0uLt4URV5WROIXxLkoDIL3p09fJrGESiFVgI1lijBYT+rWHwuW3ng0AMJktMFlE1Da3ob7FBK26fcr3lqIqtLRZsGp7CUZnJgaz2V7rXA4+fCo61mCuVgkwW0T8/asD+Hx3Of67YEpI7eQcahhGiGRo1Co8cflIAPY7nvrt/JIP316xOsXj4iQDE2+YnG332Oq7zsHqn8rsFlD7xdgMvLX1GKZJKi3SqkMPyRgOV+M0pK9rfVN19RxvyuhyISjcZnmEIo1aBY26vauwr2QbpCvGZQIArp+UrfDM0GVbDj6MKiPW/xcuG5OOT3edQJtZxN4TdXhlwxE8qLCC8sGT9Sg61YgZg1IU/xCIdNH5UxMFmfTDV6dxMXZD0k2T4LDza7/kOPzuwsFOx392zwy7+6QDWPunxOL2af0Rb9C4XNsjVq/GH+cOw3PfHMKf5g23zRBSyi9yY0a++/15ssfKDmANw43yKPBsy8GH1ZiR9ipOdlIsvrrvXLzzYyle3VCEF9cdwdai0/jFuAzcMjXHdnzRqQbMWboBoggM6B2HV26agEF95RcqjGQMI0RBIA0CrioU0g9uuWmynpBWItQqFf40z3mJdkdxOg0WzBiA26b1x6HKziWtldoq100zoLf8OivyM4IYRsiZ9Xc3vGbTtP9XrRIwoHcP5OUORcGxahQcq8ZPJTX4qaQGoghcPTETDUYT9pXX2calFZ1qxGXLfsD2R2Yj3hBdXToMI0RBIP08dlcVGNinBw5XNmDqgGSXxymRdtN4OjbDWipWqwS7AKI05tWbDwtvZvxQdLPOpjF27HVU09SKxBhtSA8GtY5vsYZuQRCwfP7ZeK+gFOsPnsLGQ1V47OO9eOKTvXZdwJP6J2F78Rk0t5lxuLIB47J7BaP5QcMh7ERuPHfdWADA364a7bdzSt9MtW5mkny6aDp2PnYResUpjy1xRauSVkY8DCOS7iGNyr6yIsebFTLlwkikLgdPXdM3oX39nfLaFvxz7UGMfXIt7n9vV0jvhmuyja/q/J1OjNViwYwBWHn7JNu+VI75fXL/JEzq3z4o+X/5x8Oqa8ofWBkhcuPysRmYMyLVbiaLP6ndVEYMWnWXXls6hdfTCoR0fRNpUFBawbNNYQVWOXJNYBghOZm92rc0OHKqAZ/vLgcAfPDTcYzN7ombp/QLZtMUmSWzaRwJgoDH5o3AghkDoBKAHw6fxv3v7QQADO4bj5N1LdhefAartpdg1/Ea5CS3z6DrHa9HnE6NERkJmNw/GVq1Cs2tZsTp1TBZRBi0algsouKsvHDAMELkgUAFEcC+chEImi5WRqTLtysVcS4fm4H9X+736NzspiFPZXWEEccN5/7vk30Yk5mI0Zk9g9Aq11yFEauMjp2rfzkhE/1TYnGipgW5I1MRp1dj9U9lMFnaZ+DIbbQXr9dABNBgbF9LRqMS0DfBgBO1zcjqFYvURANaTRboNSoM7NMDv79oCBqNJhSW1mDtvpO4akImDBoVspNjYdCo0TM2NLq9fAojL774Iv7+97+jvLwcI0aMwNKlSzFjxgzF41944QUsW7YMR48eRXZ2Nh555BHccsstPjeaKJK4WnzMP+fvfKPxNFTF6hQqIwpvsL+e0R9DUnvg9hX5Ls87NDVe9hysjJCczF72K5deMioVJrOIr/edxL3vFGLt784N+P8/3jLLdNO4MqFfEiZ0FHnOH9oXh/6ci5/L6/HZ7hPoFdu+llB9SxsaWkzIP1aN49XNds83WUSU1bTfV3KmybYyLwBsKz6Dt7eV2B3/8c4TdreT4nToGatFjFaN++cMcbuVRaB4HUbeffdd3HfffXjxxRcxbdo0vPLKK8jNzcW+ffuQne08j/2ll15CXl4eXnvtNZx99tnYvn07fv3rX6NXr16YN2+eX34IonAW6Gmt9ZLVOMdm93R7vEoARmZ0LlQhfVMVFHbt0ahVOH9o55L2Sm/EHy2chi1HTjvdzzBCcnrGatFDr7FVAUakJ+KmKf2Q/8w6FFc14su9Fbh0dHqQW2mvc9Ez30KSIAgYnp6A4ekJTo+ZLSJ+KqmGSgCGpiagwWjCqXojymtb0Ga24PlvDyGlhx71RhN2ltYovoZOo0JrxxYXZxpbcaaxFQDQLNkEs7t5HUaeffZZ/OpXv8KCBQsAAEuXLsVXX32Fl156CUuWLHE6/s0338Qdd9yBa6+9FgAwYMAAbN26FX/9618ZRoggv8S7P03M6YV4gwYzBqU4rVUiZ+vD9tMKvQlLf5w7DE999jOeu26c7b4rxmXgwx1l+PMVI6HXqDmAlTwmCAIye8Vgf0X79PIxmT2RGKPFzVP64blvD2HJ5/tR09SG2cP6hMz+LxYvKyPeUKsEnC3ZjiFOr0HfBANGZrSvrHvJqDTbY6IoosFoQumZZiT30EEA0CfBYHvsyKlG9O6hx/6KOrSaLTBbRNkA1F28CiOtra0oKCjAQw89ZHf/RRddhM2bN8s+x2g0wmAw2N0XExOD7du3o62tDVqt85uj0WiE0di5n0JdnXO/GVGkCPSOtX3iDfjxkQugl1lszNHAPj3QJ97+/1dp+0S4HuG/YMYAXD8p224VyWeuHoNF5w9E/5Q4AMCwNOc3PIYRUtK+o3V7GJmY0z7d9Zap/fDy+iMoq2nGH9fswUvrYvD1784NidVLrZWRYA8mFQQB8QYthqc7f8YKgoCBfdrXAZrs45IB/ubVu2BVVRXMZjP69rXfYbRv376oqKiQfc6cOXPw+uuvo6CgAKIoIj8/H8uXL0dbWxuqqqpkn7NkyRIkJibavrKysrxpJlFY6Y7VRw1atUeD1OSmTEqDgiczKh0/EKyLP1lfv3e8HhsemIWhqfF2xxDJuWf2IEzs1wt5uUNtY56Se+jxh4uH2jaJLKtpxrs/lgaxlZ28HTNC7Xz6k8zxTU0URcU3ukcffRS5ubmYMmUKtFotLr/8ctx6660AALVafjBdXl4eamtrbV+lpaHxS0YUCKH0ppWdFOt0n8bLMOLR6yTHdvzFa32N0BqESKFjUv8kvP/bc3DHeWfZ3X/79P7Y8/gc/PmK9j2knvx0H655ZQs+3XVC7jTdxuSw6Bl5xqt3gJSUFKjVaqcqSGVlpVO1xComJgbLly9HU1MTjh49ipKSEuTk5CA+Ph4pKfLbpuv1eiQkJNh9EUWqWF3gpg176n93TMXc0Wl4WmZhN2m52Tol0R+kf7/wfZt8EafX4KrxmeiX3B6itxefwT2rduDNLUex63hNUBZHs+6MEEp/ZIQDrzrYdDodJkyYgLVr1+KKK66w3b927VpcfvnlLp+r1WqRmdm+e+Q777yDSy+9FCr+NURRbNH5A7Hh4Cn8ckLwuyEnSVZ/lPPDQ+ejpc3s1y3QpdXUUFjngMKTQavGu7+ZivcLSvHl3grsKavDox/tBQBcOLwvll47tlvHklgrI8EeMxJuvP4XWrx4MW6++WZMnDgRU6dOxauvvoqSkhLceeedANq7WMrKyrBy5UoAwMGDB7F9+3ZMnjwZ1dXVePbZZ7Fnzx785z//8e9PQhRmfn/REPz+oiHBboZH/FkRseJbNflLaqIBC88fhAUzBuDZtQexteg09pfXty/y9dJm3D1rIC4a0Rd6TeCrkBwz4huvw8i1116L06dP48knn0R5eTlGjhyJzz//HP36ta/aUl5ejpKSzkVWzGYz/vGPf+DAgQPQarWYNWsWNm/ejJycHL/9EEQUflgMIX8zaNV4+JJhAICCY9W448187K+ox6JVO5CWaMC0gSnoHa/H9WdnIzvZeXyUP5hF9yuwkjNBDOUdhzrU1dUhMTERtbW1HD9CFCFue2M7vj9wCgBw9Om5QW4NRaKTdS14c8sxvJtfilP1nctFaNUCrpmYhaFpCZg+MMU27dwfLl66Afsr6vHWryZj+iD5cZHRxNPP7+BPyiaiqMRxIhRofRMMuH/OENw9ayC+21+JolMN2Hi4CtsdlknP7BUDnVoFnUaFSf2ToNeocPnYDPTQaxCn16B3vN7Fq9gz29YZ8fuPE9EYRogoKBhFqLvE6NSYO7p9ddJFswdhy5HTeC+/FEeqGrGztMZuvxfraq+vbSy23ZfSQ4+WNjNyR6ZiyoBkjM5MxInaFqQlGjC4b7zda3WOGWEa8QbDCBEFBQsjFCxTz0rG1LPaVx79em8FCktrcM5ZKTjV0IKNB6twqLIBu8tqbcdXNbR38bxXcBzvFRy33a8SgGkD27tixmT2xMiMBBRVNQLgmBFvMYwQUZDwzZqC76IRqbhoRKrt9hXj2pegKD3TBKPJgji9GiWnm1BR14KVW47hdIMRR0+374xrEYGNh9pXErf+1yrQe05FGoYRIgoKVkYolGVJViO2bsJ3+dgMAO2VklidGp/sPIGfy+uRHKfDt/srcby6CRYROOesZAxJjZc9L8ljGCGioGAWoXBl3crg2rOzbfctmj0oWM2JCKwjEVFQsDJCRFYMI0QUFCqmESLqwDBCREHBLEJEVgwjREREFFQMI0QUFFyBlYisGEaIKCgYRYjIimGEiIJiYr9ewW4CEYUIrjNCREFx05R+0GnUmDwgKdhNIaIgYxghoqDQqFW4YXK2+wOJKOKxm4aIiIiCimGEiIiIgophhIiIiIKKYYSIiIiCimGEiIiIgophhIiIiIKKYYSIiIiCimGEiIiIgophhIiIiIKKYYSIiIiCimGEiIiIgophhIiIiIKKYYSIiIiCKix27RVFEQBQV1cX5JYQERGRp6yf29bPcSVhEUbq6+sBAFlZWUFuCREREXmrvr4eiYmJio8Loru4EgIsFgtOnDiB+Ph4CILgt/PW1dUhKysLpaWlSEhI8Nt5yRmvdffgde4evM7dg9e5+wTqWouiiPr6eqSnp0OlUh4ZEhaVEZVKhczMzICdPyEhgb/o3YTXunvwOncPXufuwevcfQJxrV1VRKw4gJWIiIiCimGEiIiIgiqqw4her8djjz0GvV4f7KZEPF7r7sHr3D14nbsHr3P3Cfa1DosBrERERBS5oroyQkRERMHHMEJERERBxTBCREREQcUwQkREREEV1WHkxRdfRP/+/WEwGDBhwgRs3Lgx2E0KG0uWLMHZZ5+N+Ph49OnTB7/4xS9w4MABu2NEUcTjjz+O9PR0xMTEYObMmdi7d6/dMUajEYsWLUJKSgri4uJw2WWX4fjx4935o4SVJUuWQBAE3Hfffbb7eJ39p6ysDDfddBOSk5MRGxuLsWPHoqCgwPY4r3XXmUwm/PGPf0T//v0RExODAQMG4Mknn4TFYrEdw+vsmw0bNmDevHlIT0+HIAhYs2aN3eP+uq7V1dW4+eabkZiYiMTERNx8882oqanpWuPFKPXOO++IWq1WfO2118R9+/aJ9957rxgXFyceO3Ys2E0LC3PmzBHfeOMNcc+ePWJhYaE4d+5cMTs7W2xoaLAd8/TTT4vx8fHiBx98IO7evVu89tprxbS0NLGurs52zJ133ilmZGSIa9euFX/66Sdx1qxZ4pgxY0STyRSMHyukbd++XczJyRFHjx4t3nvvvbb7eZ3948yZM2K/fv3EW2+9Vdy2bZtYXFwsfvPNN+Lhw4dtx/Bad91TTz0lJicni59++qlYXFwsvvfee2KPHj3EpUuX2o7hdfbN559/Lj7yyCPiBx98IAIQP/zwQ7vH/XVdL774YnHkyJHi5s2bxc2bN4sjR44UL7300i61PWrDyKRJk8Q777zT7r6hQ4eKDz30UJBaFN4qKytFAOL69etFURRFi8Uipqamik8//bTtmJaWFjExMVF8+eWXRVEUxZqaGlGr1YrvvPOO7ZiysjJRpVKJX375Zff+ACGuvr5eHDRokLh27VrxvPPOs4URXmf/+cMf/iBOnz5d8XFea/+YO3euePvtt9vdd+WVV4o33XSTKIq8zv7iGEb8dV337dsnAhC3bt1qO2bLli0iAHH//v0+tzcqu2laW1tRUFCAiy66yO7+iy66CJs3bw5Sq8JbbW0tACApKQkAUFxcjIqKCrtrrNfrcd5559mucUFBAdra2uyOSU9Px8iRI/nv4ODuu+/G3LlzccEFF9jdz+vsPx9//DEmTpyIq6++Gn369MG4cePw2muv2R7ntfaP6dOn49tvv8XBgwcBADt37sSmTZtwySWXAOB1DhR/XdctW7YgMTERkydPth0zZcoUJCYmdunah8VGef5WVVUFs9mMvn372t3ft29fVFRUBKlV4UsURSxevBjTp0/HyJEjAcB2HeWu8bFjx2zH6HQ69OrVy+kY/jt0euedd/DTTz/hxx9/dHqM19l/ioqK8NJLL2Hx4sV4+OGHsX37dtxzzz3Q6/W45ZZbeK395A9/+ANqa2sxdOhQqNVqmM1m/PnPf8b1118PgL/TgeKv61pRUYE+ffo4nb9Pnz5duvZRGUasBEGwuy2KotN95N7ChQuxa9cubNq0yekxX64x/x06lZaW4t5778XXX38Ng8GgeByvc9dZLBZMnDgRf/nLXwAA48aNw969e/HSSy/hlltusR3Ha9017777Lt566y3897//xYgRI1BYWIj77rsP6enpmD9/vu04XufA8Md1lTu+q9c+KrtpUlJSoFarnVJcZWWlU2ok1xYtWoSPP/4Y33//PTIzM233p6amAoDLa5yamorW1lZUV1crHhPtCgoKUFlZiQkTJkCj0UCj0WD9+vV4/vnnodFobNeJ17nr0tLSMHz4cLv7hg0bhpKSEgD8nfaXBx54AA899BCuu+46jBo1CjfffDN+97vfYcmSJQB4nQPFX9c1NTUVJ0+edDr/qVOnunTtozKM6HQ6TJgwAWvXrrW7f+3atTjnnHOC1KrwIooiFi5ciNWrV+O7775D//797R7v378/UlNT7a5xa2sr1q9fb7vGEyZMgFartTumvLwce/bs4b9Dh9mzZ2P37t0oLCy0fU2cOBE33ngjCgsLMWDAAF5nP5k2bZrT9PSDBw+iX79+APg77S9NTU1Qqew/etRqtW1qL69zYPjruk6dOhW1tbXYvn277Zht27ahtra2a9fe56GvYc46tfff//63uG/fPvG+++4T4+LixKNHjwa7aWHht7/9rZiYmCiuW7dOLC8vt301NTXZjnn66afFxMREcfXq1eLu3bvF66+/XnYaWWZmpvjNN9+IP/30k3j++edH/fQ8d6SzaUSR19lftm/fLmo0GvHPf/6zeOjQIfHtt98WY2Njxbfeest2DK91182fP1/MyMiwTe1dvXq1mJKSIj744IO2Y3idfVNfXy/u2LFD3LFjhwhAfPbZZ8UdO3bYlqzw13W9+OKLxdGjR4tbtmwRt2zZIo4aNYpTe7vihRdeEPv16yfqdDpx/Pjxtmmp5B4A2a833njDdozFYhEfe+wxMTU1VdTr9eK5554r7t692+48zc3N4sKFC8WkpCQxJiZGvPTSS8WSkpJu/mnCi2MY4XX2n08++UQcOXKkqNfrxaFDh4qvvvqq3eO81l1XV1cn3nvvvWJ2drZoMBjEAQMGiI888ohoNBptx/A6++b777+XfV+eP3++KIr+u66nT58Wb7zxRjE+Pl6Mj48Xb7zxRrG6urpLbRdEURR9r6sQERERdU1UjhkhIiKi0MEwQkREREHFMEJERERBxTBCREREQcUwQkREREHFMEJERERBxTBCREREQcUwQkREREHFMEJERERBxTBCREREQcUwQkREREHFMEJERERB9f+DFfJFFVJMggAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(learning_rate)\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "784790cd-9dd5-401d-9995-b0d4de79a3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model's state_dict\n",
    "torch.save(policy_net.state_dict(), 'land_select_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bbb969a2-4a07-45ee-945d-068b25310413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0, Loss: 1.0465924739837646, minprob: 0.2598021626472473\n",
      "tensor([0.0000, 0.0000, 0.0000, 0.5000, 0.2917, 0.0000])\n",
      "tensor([0.0000, 0.0000, 0.0000, 0.4000, 0.4000, 0.0000])\n",
      "tensor([0.0000, 0.0000, 0.0000, 0.3931, 0.1639, 0.0000])\n",
      "tensor([0.0000, 0.3500, 0.1583, 0.1250, 0.4000, 1.2000])\n",
      "tensor([5.3880e-02, 7.6894e-02, 1.4334e-02, 1.5290e+01, 9.0798e+00, 5.5011e-03],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor(0.6235, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#Further Training\n",
    "#policy_net.add_postprocess()\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-5  # You can adjust this value as needed\n",
    "optimizer = optim.Adam(policy_net.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "deck_refresh = 100\n",
    "for episode in range(num_episodes):\n",
    "    if episode % deck_refresh == 0: #Keep decks for a short length of time, so that training can go towards something consistent for a while\n",
    "        total_lands = int(random.random()*10)+15 #Currently randomised, should this be fed into the model?\n",
    "        # Generate random cost_ratios\n",
    "        color_combinations = get_color_combinations(colors)\n",
    "        color_combinations+= [random.choices([\"W\", \"U\",\"B\", \"R\",\"G\"],k=2) for _ in range(32)]\n",
    "        decks = [\n",
    "            select_cards(shortened_card_data, total_lands, \n",
    "                         {'color': c},\n",
    "                         exclusive = {'color': True}, blankparams = False,  negparams = {\"card_type\":[\"Land\", \"Token\", \"Emblem\"]}\n",
    "                        ) for c in color_combinations]\n",
    "        states = [# Sample state (land_ratios) from the policy\n",
    "            torch.tensor(np.concatenate((deck_costs(deck)[0], np.asarray([total_lands*0.05]))), dtype=torch.float32).unsqueeze(\n",
    "                0)\n",
    "            for deck in decks\n",
    "        ]\n",
    "        \n",
    "    \n",
    "    \n",
    "    batch_losses = []\n",
    "    batch_minprob = []\n",
    "    for state, deck in zip(states, decks):\n",
    "        # Sample action (land_ratios) from the policy\n",
    "        land_ratios = policy_net(state).requires_grad_().squeeze(0)\n",
    "        land_ratios = torch.abs(land_ratios)#.requires_grad_()\n",
    "\n",
    "        # Perform any necessary normalization or conversion to integers, etc. here\n",
    "        land_ratios = torch.mul(land_ratios, total_lands*0.2).requires_grad_()\n",
    "        land_ratios = soft_integer_round(land_ratios)\n",
    "        loss, minprob = eval_deck_tensor(deck, land_ratios)\n",
    "        loss = torch.add(loss, torch.pow(torch.sub(torch.div(torch.sum(land_ratios),total_lands),1),2), alpha=2)\n",
    "        batch_losses.append(loss)\n",
    "        batch_minprob.append(minprob[0])\n",
    "    \n",
    "    \n",
    "    # Update the model's parameters\n",
    "    avg_loss = torch.stack(batch_losses).mean()\n",
    "    optimizer.zero_grad()\n",
    "    avg_loss.backward()\n",
    "    optimizer.step()\n",
    "    losses.append(avg_loss.item())#.detach().numpy()[0])\n",
    "    if False and (episode+1) %500 == 0: #Readjust model periodically\n",
    "        policy_net.add_postprocess()\n",
    "        optimizer = optim.Adam(policy_net.parameters(), lr=learning_rate)\n",
    "    if 0 ==episode % (deck_refresh*100):#in ((episode+1) % (deck_refresh),episode % (deck_refresh)) :\n",
    "        print(f\"Episode {episode}, Loss: {avg_loss.item()}, minprob: {torch.stack(batch_minprob).mean()}\")\n",
    "        #policy_net.print_weights()\n",
    "        #print(land_ratios[0:-1])\n",
    "        #print(torch.tensor(minimums, dtype=torch.float32)[0:-1])\n",
    "        if 0 == episode % (deck_refresh) :\n",
    "            print(states[-1][0][0:6])\n",
    "            print(states[-1][0][6:12])\n",
    "            print(states[-1][0][12:18])\n",
    "            print(states[-1][0][18:24])\n",
    "            print(land_ratios)\n",
    "            print(loss)\n",
    "            for name, param in policy_net.named_parameters():\n",
    "                if False and param.grad is not None:\n",
    "                    print(name, param.grad.norm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba894f79-f86f-45c8-bf8b-c7f62bf624fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "40e9890c-aecb-4527-b301-c6b87d7dfbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0, Loss: 15.719365119934082, minprob: 0.04502977058291435, 0.00045029769535176456\n",
      "tensor([4.7630, 4.8535, 4.5350, 4.5391, 4.6155], grad_fn=<SliceBackward0>)\n",
      "tensor([2., 3., 1., 0., 3.])\n",
      "fc1.weight tensor(0.5388)\n",
      "fc1.bias tensor(0.6901)\n",
      "fc2.weight tensor(2.4276)\n",
      "fc2.bias tensor(0.2260)\n",
      "Prelearning done, episode99\n",
      "Episode 100, Loss: 0.8293336033821106, minprob: 0.0452532134950161, 0.00045253211283124983\n",
      "tensor([3.3977, 2.1430, 6.7502, 3.2627, 7.8030], grad_fn=<SliceBackward0>)\n",
      "tensor([1., 1., 3., 2., 1.])\n",
      "fc1.weight tensor(0.0002)\n",
      "fc1.bias tensor(0.0002)\n",
      "fc2.weight tensor(0.0077)\n",
      "fc2.bias tensor(4.0200e-05)\n",
      "Episode 200, Loss: 0.9991210103034973, minprob: 0.0, 0.00021983384795021266\n",
      "tensor([1.1995, 1.0475, 2.6210, 1.5133, 3.1474], grad_fn=<SliceBackward0>)\n",
      "tensor([2., 2., 0., 0., 2.])\n",
      "fc1.weight tensor(0.)\n",
      "fc1.bias tensor(0.)\n",
      "fc2.weight tensor(0.)\n",
      "fc2.bias tensor(0.)\n",
      "Episode 300, Loss: 0.9700326323509216, minprob: 0.007502510212361813, 7.502509834012017e-05\n",
      "tensor([3.2585, 2.1976, 6.7341, 5.9703, 8.1170], grad_fn=<SliceBackward0>)\n",
      "tensor([2., 2., 2., 2., 0.])\n",
      "fc1.weight tensor(0.0003)\n",
      "fc1.bias tensor(0.0004)\n",
      "fc2.weight tensor(0.0029)\n",
      "fc2.bias tensor(1.6833e-05)\n",
      "Episode 400, Loss: 0.9479218125343323, minprob: 0.013150334358215332, 0.00013150334416422993\n",
      "tensor([3.4657, 2.1709, 7.5267, 5.0806, 7.5763], grad_fn=<SliceBackward0>)\n",
      "tensor([2., 1., 2., 0., 0.])\n",
      "fc1.weight tensor(0.0001)\n",
      "fc1.bias tensor(0.0001)\n",
      "fc2.weight tensor(0.0025)\n",
      "fc2.bias tensor(1.4686e-05)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[578], line 77\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# Update the model's parameters\u001b[39;00m\n\u001b[0;32m     76\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 77\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m1\u001b[39m,episode \u001b[38;5;241m%\u001b[39m (deck_refresh\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m10\u001b[39m)) :\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\image_env\\lib\\site-packages\\torch\\_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[0;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[1;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\image_env\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the neural network architecture\n",
    "class ContinuousPolicyNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(ContinuousPolicyNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        # Initialize weights\n",
    "        init.normal_(self.fc1.weight, mean=0.5, std=0.25)\n",
    "        init.normal_(self.fc2.weight, mean=0.5, std=0.25)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def print_weights(self):\n",
    "        print(\"fc1.weight\", torch.sum(self.fc1.weight).item())\n",
    "        print(\"fc1.bias\", torch.sum(self.fc1.bias).item())\n",
    "        print(\"fc2.weight\", torch.sum(self.fc2.weight).item())\n",
    "        print(\"fc2.bias\", torch.sum(self.fc2.bias).item())\n",
    "\n",
    "\n",
    "# Define hyperparameters\n",
    "input_size = 12  # cost_ratios and minimums concatenated\n",
    "hidden_size = 128\n",
    "output_size = 6  # number of possible actions (land_ratios)\n",
    "learning_rate = 1\n",
    "num_episodes = 50000\n",
    "deck_refresh = 10\n",
    "\n",
    "# Create the policy network\n",
    "policy_net = ContinuousPolicyNetwork(input_size, hidden_size, output_size)\n",
    "optimizer = optim.Adam(policy_net.parameters(), lr=learning_rate)\n",
    "\n",
    "prelearning = 10\n",
    "batch_size = 32\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    if episode % deck_refresh == 0: #Keep decks for a short length of time, so that training can go towards something consistent for a while\n",
    "        total_lands = int(random.random()*20)+10 #Currently randomised, should this be fed into the model?\n",
    "        # Generate a random cost_ratios and minimums (replace this with your actual data)\n",
    "        newdeck = select_cards(shortened_card_data, total_lands, {'color': random.sample([\"W\", \"U\",\"B\", \"R\",\"G\", \"\"],2)},exclusive = False, blankparams = False,  negparams = {\"card_type\":[\"Land\", \"Token\", \"Emblem\"]})\n",
    "        cost_ratios, minimums = deck_costs(newdeck) #Two 1*6 nparrays\n",
    "        state = torch.tensor(np.concatenate((cost_ratios, minimums*0.1)), dtype=torch.float32).unsqueeze(0)\n",
    "        \n",
    "        \n",
    "    # Sample action (land_ratios) from the policy\n",
    "    #action_probs = policy_net(state)\n",
    "    \n",
    "    # Convert probabilities to land_ratios\n",
    "    land_ratios = policy_net(state).requires_grad_().squeeze(0)\n",
    "    land_ratios = torch.abs(land_ratios).requires_grad_()\n",
    "    #land_ratios = torch.clamp(land_ratios, 0, 1)#.requires_grad_()  # Clamp the values between 0 and 1\n",
    "    \n",
    "    # Perform any necessary normalization or conversion to integers, etc. here\n",
    "    # Example: Normalize the values to sum to a specific total number of lands\n",
    "    land_ratios = ((land_ratios / max(land_ratios.sum(),0.25)) * total_lands).requires_grad_()\n",
    "    \n",
    "    #print(land_ratios)\n",
    "    filtered_land_ratios = torch.max(land_ratios, torch.tensor(minimums, dtype=torch.float32)).requires_grad_()\n",
    "    \n",
    "    if prelearning:\n",
    "        loss = torch.nn.functional.cross_entropy(land_ratios, torch.tensor(minimums, dtype=torch.float32))\n",
    "        #_, minprob = eval_deck_tensor(newdeck, land_ratios, filtered_land_ratios)\n",
    "        if loss < 5:\n",
    "            prelearning -= 1\n",
    "            if not prelearning:\n",
    "                print(f\"Prelearning done, episode{episode}\")\n",
    "    else:\n",
    "        loss, minprob = eval_deck_tensor(newdeck, land_ratios, filtered_land_ratios)\n",
    "    \n",
    "    # Update the model's parameters\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if 0 in (1,episode % (deck_refresh*10)) :\n",
    "        print(f\"Episode {episode}, Loss: {loss.item()}, minprob: {minprob[0]}, {minprob[-1]}\")\n",
    "        #policy_net.print_weights()\n",
    "        print(land_ratios[0:-1])\n",
    "        print(torch.tensor(minimums, dtype=torch.float32)[0:-1])\n",
    "        for name, param in policy_net.named_parameters():\n",
    "            if param.grad is not None:\n",
    "                print(name, param.grad.norm())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20519635-2f19-4a42-801b-793e9a77eddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in newdeck:\n",
    "    print(i[\"color\"])\n",
    "    print(i[\"mana_cost\"])\n",
    "    print(i[\"mana_symbols\"])\n",
    "    print(i[\"name\"])\n",
    "    print(i[\"card_type\"])\n",
    "    print(i[\"oracle_text\"])\n",
    "    print(i)\n",
    "    print()\n",
    "    \n",
    "for i in landeck:\n",
    "    print(i[\"color\"])\n",
    "    print(i[\"name\"])\n",
    "    print(i[\"subtypes\"])\n",
    "    print(i)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab5e39d-4d85-4836-a6f7-8945534cdb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 10\n",
    "num_lanes = 5\n",
    "special_steps = {0: 1, num_steps - 1: 1}\n",
    "nodes, minimap, connections = generate_minimap(num_steps, num_lanes, special_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bac285-503c-41d7-a07b-3cd8a3aa8c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {'object': 'card', 'id': '29968873-56f3-4528-ab0b-f11dd67dd162', 'oracle_id': 'a7df5dc0-2564-4288-bc53-59affd896f79', 'multiverse_ids': [368982], 'mtgo_id': 48512, 'tcgplayer_id': 67947, 'cardmarket_id': 261492, 'name': 'Catch // Release', 'lang': 'en', 'released_at': '2013-05-03', 'uri': 'https://api.scryfall.com/cards/29968873-56f3-4528-ab0b-f11dd67dd162', 'scryfall_uri': 'https://scryfall.com/card/dgm/125/catch-release?utm_source=api', 'layout': 'split', 'highres_image': True, 'image_status': 'highres_scan', 'image_uris': {'small': 'https://cards.scryfall.io/small/front/2/9/29968873-56f3-4528-ab0b-f11dd67dd162.jpg?1562902690', 'normal': 'https://cards.scryfall.io/normal/front/2/9/29968873-56f3-4528-ab0b-f11dd67dd162.jpg?1562902690', 'large': 'https://cards.scryfall.io/large/front/2/9/29968873-56f3-4528-ab0b-f11dd67dd162.jpg?1562902690', 'png': 'https://cards.scryfall.io/png/front/2/9/29968873-56f3-4528-ab0b-f11dd67dd162.png?1562902690', 'art_crop': 'https://cards.scryfall.io/art_crop/front/2/9/29968873-56f3-4528-ab0b-f11dd67dd162.jpg?1562902690', 'border_crop': 'https://cards.scryfall.io/border_crop/front/2/9/29968873-56f3-4528-ab0b-f11dd67dd162.jpg?1562902690'}, 'mana_cost': '{1}{U}{R} // {4}{R}{W}', 'cmc': 9.0, 'type_line': 'Sorcery // Sorcery', 'colors': ['R', 'U', 'W'], 'color_identity': ['R', 'U', 'W'], 'keywords': ['Fuse'], 'card_faces': [{'object': 'card_face', 'name': 'Catch', 'mana_cost': '{1}{U}{R}', 'type_line': 'Sorcery', 'oracle_text': 'Gain control of target permanent until end of turn. Untap it. It gains haste until end of turn.\\nFuse (You may cast one or both halves of this card from your hand.)', 'watermark': 'izzet', 'artist': 'Kev Walker', 'artist_id': 'f366a0ee-a0cd-466d-ba6a-90058c7a31a6', 'illustration_id': 'cc953d3c-7790-4cec-818a-1a112ad57a2e'}, {'object': 'card_face', 'name': 'Release', 'flavor_name': '', 'mana_cost': '{4}{R}{W}', 'type_line': 'Sorcery', 'oracle_text': 'Each player sacrifices an artifact, a creature, an enchantment, a land, and a planeswalker.\\nFuse (You may cast one or both halves of this card from your hand.)', 'watermark': 'boros', 'artist': 'Kev Walker', 'artist_id': 'f366a0ee-a0cd-466d-ba6a-90058c7a31a6'}], 'legalities': {'standard': 'not_legal', 'future': 'not_legal', 'historic': 'not_legal', 'gladiator': 'not_legal', 'pioneer': 'legal', 'explorer': 'not_legal', 'modern': 'legal', 'legacy': 'legal', 'pauper': 'not_legal', 'vintage': 'legal', 'penny': 'legal', 'commander': 'legal', 'oathbreaker': 'legal', 'brawl': 'not_legal', 'historicbrawl': 'not_legal', 'alchemy': 'not_legal', 'paupercommander': 'not_legal', 'duel': 'legal', 'oldschool': 'not_legal', 'premodern': 'not_legal', 'predh': 'not_legal'}, 'games': ['paper', 'mtgo'], 'reserved': False, 'foil': True, 'nonfoil': True, 'finishes': ['nonfoil', 'foil'], 'oversized': False, 'promo': False, 'reprint': False, 'variation': False, 'set_id': 'c8bd8520-cd98-45cd-b533-8d40c2087426', 'set': 'dgm', 'set_name': \"Dragon's Maze\", 'set_type': 'expansion', 'set_uri': 'https://api.scryfall.com/sets/c8bd8520-cd98-45cd-b533-8d40c2087426', 'set_search_uri': 'https://api.scryfall.com/cards/search?order=set&q=e%3Adgm&unique=prints', 'scryfall_set_uri': 'https://scryfall.com/sets/dgm?utm_source=api', 'rulings_uri': 'https://api.scryfall.com/cards/29968873-56f3-4528-ab0b-f11dd67dd162/rulings', 'prints_search_uri': 'https://api.scryfall.com/cards/search?order=released&q=oracleid%3Aa7df5dc0-2564-4288-bc53-59affd896f79&unique=prints', 'collector_number': '125', 'digital': False, 'rarity': 'rare', 'card_back_id': '0aeebaf5-8c7d-4636-9e82-8c27447861f7', 'artist': 'Kev Walker', 'artist_ids': ['f366a0ee-a0cd-466d-ba6a-90058c7a31a6'], 'illustration_id': 'cc953d3c-7790-4cec-818a-1a112ad57a2e', 'border_color': 'black', 'frame': '2003', 'full_art': False, 'textless': False, 'booster': True, 'story_spotlight': False, 'edhrec_rank': 16903, 'penny_rank': 3634, 'prices': {'usd': '0.18', 'usd_foil': '0.34', 'usd_etched': None, 'eur': '0.25', 'eur_foil': '0.79', 'tix': '0.01'}, 'related_uris': {'gatherer': 'https://gatherer.wizards.com/Pages/Card/Details.aspx?multiverseid=368982', 'tcgplayer_infinite_articles': 'https://infinite.tcgplayer.com/search?contentMode=article&game=magic&partner=scryfall&q=Catch+%2F%2F+Release&utm_campaign=affiliate&utm_medium=api&utm_source=scryfall', 'tcgplayer_infinite_decks': 'https://infinite.tcgplayer.com/search?contentMode=deck&game=magic&partner=scryfall&q=Catch+%2F%2F+Release&utm_campaign=affiliate&utm_medium=api&utm_source=scryfall', 'edhrec': 'https://edhrec.com/route/?cc=Catch+%2F%2F+Release'}, 'purchase_uris': {'tcgplayer': 'https://www.tcgplayer.com/product/67947?page=1&utm_campaign=affiliate&utm_medium=api&utm_source=scryfall', 'cardmarket': 'https://www.cardmarket.com/en/Magic/Products/Search?referrer=scryfall&searchString=Catch+%2F%2F+Release&utm_campaign=card_prices&utm_medium=text&utm_source=scryfall', 'cardhoarder': 'https://www.cardhoarder.com/cards/48512?affiliate_id=scryfall&ref=card-profile&utm_campaign=affiliate&utm_medium=card&utm_source=scryfall'}}\n",
    "for i in a[\"card_faces\"]:\n",
    "    for c, v in i.items():\n",
    "        print(c+\": \"+str(v))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97f4551-130a-4d95-b33e-563d702d17f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"merged_card_data.json\", \"r\") as file:\n",
    "    card_data = json.load(file)\n",
    "\n",
    "def filter_cards(cards, sets, rarity, color):\n",
    "    filtered_cards = [\n",
    "        card_e for card_e in cards\n",
    "        if card_e[\"set\"] in sets\n",
    "        and card_e[\"object\"] != \"card\"\n",
    "    ]\n",
    "    return random.choice(filtered_cards) if filtered_cards else None\n",
    "def split_type_line(type_line):\n",
    "    if 'â€”' in type_line:\n",
    "        card_type, subtypes_str = type_line.split('â€”', 1)\n",
    "        subtypes = subtypes_str.strip().split(' ')\n",
    "        for subtype in subtypes:\n",
    "            subtype = subtype.strip()\n",
    "    else:\n",
    "        card_type = type_line\n",
    "        subtypes = []\n",
    "    if \"Legendary\" in card_type:\n",
    "        card_type = card_type[9:]\n",
    "        legend = True\n",
    "    else:\n",
    "        legend = False\n",
    "    card_type = card_type.strip().split(' ')\n",
    "    for cardtype in card_type:\n",
    "        cardtype = cardtype.strip()\n",
    "    return card_type, subtypes, legend\n",
    "shortened_card_data = []\n",
    "for card in card_data:\n",
    "    \n",
    "    card_type, subtypes, legend = split_type_line(card[\"type_line\"])\n",
    "    try:\n",
    "        shortened_card = {\n",
    "            \"set\": [card[\"set\"]],\n",
    "            \"rarity\": [card[\"rarity\"]],\n",
    "            \"color\": card[\"color_identity\"],\n",
    "            \"mana_cost\": [i for i in card[\"mana_cost\"] if i in \"0123456789/WUBRGNPSXYZC\"],\n",
    "            \"mana_symbols\": [i for i in card[\"mana_cost\"] if i in \"WUBRGNPSC\"],\n",
    "            \"name\": [card[\"name\"]],\n",
    "            \"cmc\": [card[\"cmc\"]],\n",
    "            \"card_type\": card_type,\n",
    "            \"subtypes\": subtypes,\n",
    "            \"keywords\": card[\"keywords\"],\n",
    "            \"watermark\": [card_face[\"watermark\"] for card_face in card[\"card_faces\"]] if \"card_faces\" in card else [card[\"watermark\"]] if \"watermark\" in card else [],\n",
    "            \"oracle_text\": [card_face[\"oracle_text\"] for card_face in card[\"card_faces\"]] if \"card_faces\" in card else [card[\"oracle_text\"]],\n",
    "            \"legend\": [legend]\n",
    "        }\n",
    "    except:\n",
    "        print(card)\n",
    "    shortened_card_data.append(shortened_card)\n",
    "\n",
    "# Save the shortened card data to a new JSON file\n",
    "with open(\"shortened_card_data.json\", \"w\") as file:\n",
    "    json.dump(shortened_card_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749dfa31-8d6f-4ba6-ac49-3f2c5781c8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_sets = [\"lrw\", \"mor\"]\n",
    "target_rarity = [\"rare\"]\n",
    "target_color = [[\"G\"]]\n",
    "\n",
    "selected_card = filter_cards(card_data, target_sets, target_rarity, target_color)\n",
    "\n",
    "if selected_card:\n",
    "    print(f\"Selected card: {selected_card['name']} from {selected_card['set']}\")\n",
    "else:\n",
    "    print(\"No card found that matches the given criteria.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f57643c-123f-428e-a1ec-ed5fb0512c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "if set([\"G\"]).intersection(set([])):\n",
    "    print(\"yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507e310e-6e65-4142-84ef-7c68170776d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match(card_e, params, exclusive, negparams=None, blankparams=None):\n",
    "    all_params = set(params.keys())\n",
    "    if negparams:\n",
    "        all_params = all_params.union(set(negparams.keys()))\n",
    "    if blankparams:\n",
    "        all_params = all_params.union(set(blankparams.keys()))\n",
    "    for param in all_params:\n",
    "        if param in card_e:\n",
    "            values = params.get(param, [])\n",
    "            if isinstance(exclusive, dict):\n",
    "                if (param in exclusive) and (param in params):\n",
    "                    exclusive_param = exclusive[param]\n",
    "                else:\n",
    "                    exclusive_param = False#Default to inclusive mode\n",
    "            else:\n",
    "                exclusive_param = exclusive\n",
    "\n",
    "            if negparams and (param in negparams) and (negparams[param]):\n",
    "                if set(card_e[param]).intersection(set(negparams[param])):\n",
    "                    return False\n",
    "\n",
    "            if blankparams and (param in blankparams):\n",
    "                if blankparams[param]:\n",
    "                    if len(card_e[param]) == 0:\n",
    "                        return False\n",
    "\n",
    "            if len(card_e[param]):\n",
    "                if exclusive_param:\n",
    "                    if not set(card_e[param]).issubset(set(values)):\n",
    "                        return False\n",
    "                elif len(values): #Blanks checked separately, therefore only check for overlap with values :\n",
    "                    if not set(card_e[param]).intersection(set(values)):\n",
    "                        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "\n",
    "def select_cards(cards, n, params, exclusive=True, negparams=None, blankparams=None):\n",
    "    matching_cards = [card_e for card_e in cards if match(card_e, params, exclusive, negparams, blankparams)]\n",
    "    if len(matching_cards) < n:\n",
    "        return random.choice(matching_cards, len(matching_cards))\n",
    "    else:\n",
    "        return random.sample(matching_cards, n)\n",
    "\n",
    "with open(\"shortened_card_data.json\", \"r\") as file:\n",
    "    shortened_card_data = json.load(file)\n",
    "\n",
    "fightparams = {\"set\": [],\n",
    "        \"rarity\": [],\n",
    "        \"color\": [],\n",
    "        \"mana_cost\": [\"4\"],\n",
    "        \"mana_symbols\": [],\n",
    "        \"name\": [],\n",
    "        \"cmc\": [],\n",
    "        \"card_type\": [\"Basic\"],\n",
    "        \"subtypes\": [],\n",
    "        \"watermark\": [],\n",
    "        \"keywords\": [],\n",
    "        \"oracle_text\": [],\n",
    "        \"legend\": []}#Values that are desired, such that at least one should be present if a card has any values for that parameter\n",
    "\n",
    "exclusive_params = {\"set\": False,\n",
    "        \"rarity\": False,\n",
    "        \"color\": True,\n",
    "        \"mana_cost\": False,\n",
    "        \"mana_symbols\": False,\n",
    "        \"name\": False,\n",
    "        \"cmc\": False,\n",
    "        \"card_type\": False,\n",
    "        \"subtypes\": False,\n",
    "        \"keywords\": False,\n",
    "        \"oracle_text\": False,\n",
    "        \"legend\": False}#Whether the parameter list is exclusive, ie any values outside of that list are disallowed if exclusive_params[params]==True\n",
    "blankparams = {\"set\": False,\n",
    "        \"rarity\": False,\n",
    "        \"color\": True,\n",
    "        \"mana_cost\": False,\n",
    "        \"mana_symbols\": False,\n",
    "        \"name\": False,\n",
    "        \"cmc\": False,\n",
    "        \"card_type\": False,\n",
    "        \"subtypes\": False,\n",
    "        \"keywords\": False,\n",
    "        \"oracle_text\": False,\n",
    "        \"legend\": False} #Dict of whether blank values are disallowed, eg colorless cards or no subtypes\n",
    "negparams = {\"set\": [],\n",
    "        \"rarity\": [],\n",
    "        \"color\": [],\n",
    "        \"mana_cost\": [],\n",
    "        \"mana_symbols\": [],\n",
    "        \"name\": [],\n",
    "        \"cmc\": [],\n",
    "        \"card_type\": [\"Token\"],\n",
    "        \"subtypes\": [],\n",
    "        \"keywords\": [],\n",
    "        \"oracle_text\": [],\n",
    "        \"legend\": []} #Values that are specifically not allowed\n",
    "fightparams = {\"color\": [],\n",
    "        \"mana_cost\": [],\n",
    "        \"card_type\": [],\n",
    "        \"watermark\": [\"boros\"],\n",
    "        \"set\":[],\n",
    "        \"keywords\": []}#Values that are desired, such that at least one should be present if a card has any values for that parameter\n",
    "\n",
    "exclusive_params = {\"color\": True,\n",
    "        \"mana_cost\": False,\n",
    "        \"mana_symbols\": False,\n",
    "        \"watermark\": False,\n",
    "        \"subtypes\": False}#Whether the parameter list is exclusive, ie any values outside of that list are disallowed if exclusive_params[params]==True\n",
    "blankparams = {\"color\": False,\n",
    "        \"mana_cost\": False,\n",
    "        \"mana_symbols\": False,\n",
    "        \"name\": False,\n",
    "        \"cmc\": False,\n",
    "        \"watermark\": True,\n",
    "        \"card_type\": False,\n",
    "        \"keywords\": False} #Dict of whether blank values are disallowed, eg colorless cards or no subtypes\n",
    "negparams = {\"color\": [],\n",
    "        \"mana_cost\": [],\n",
    "        \"card_type\": [\"Token\",\"Emblem\"],\n",
    "        \"subtypes\": []} #Values that are specifically not allowed\n",
    "n = 5\n",
    "selected_cards = select_cards(shortened_card_data, n, fightparams, exclusive=False,\n",
    "                              negparams=None, blankparams=blankparams)\n",
    "\n",
    "\n",
    "for card in selected_cards:\n",
    "    print(card[\"color\"])\n",
    "    print(card[\"subtypes\"])\n",
    "    print(card[\"card_type\"])\n",
    "    print(card[\"mana_cost\"])\n",
    "    print(card[\"name\"])\n",
    "    print(card[\"oracle_text\"])\n",
    "    print(card[\"set\"])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba64882b-1b67-4af7-ab93-f8ecd85744ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniques = []\n",
    "param = \"watermark\"\n",
    "for card in shortened_card_data:\n",
    "    for entry in card[param]:\n",
    "        if not entry in uniques:\n",
    "            uniques.append(entry)\n",
    "            print(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582ad7c6-58df-4f55-ab20-110bf84e79cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n = 50\n",
    "\n",
    "\n",
    "# You'll need to execute this in multiple runs, one for each color and colorless cards, and then combine the results.\n",
    "colors = [\"W\", \"U\", \"B\", \"R\", \"G\", []]  # Include an empty list for colorless cards\n",
    "params = {\"color\":[\"G\", \"R\",\"W\"], \"set\":[\"lrw\",\"mrn\"], \"cmc\":[1,2,3,4,5]}\n",
    "exclusive = {\"name\": True, \"color\": True, \"set\": True, \"subtypes\": True}\n",
    "blankparams = {\"color\": True, \"subtypes\": False}\n",
    "negparams = {\"card_type\": [\"Land\", \"Token\"]}\n",
    "\n",
    "# Expected output: A deck containing an equal number of cards from each color and colorless cards, with no artifacts.\n",
    "selected_cards=select_cards(shortened_card_data, 15, params, exclusive=exclusive,\n",
    "                              negparams=negparams, blankparams=blankparams)\n",
    "\n",
    "print(len(selected_cards))\n",
    "for card in selected_cards:\n",
    "    print(card[\"color\"])\n",
    "    print(card[\"mana_cost\"])\n",
    "    print(card[\"card_type\"])\n",
    "    print(card[\"subtypes\"])\n",
    "    print(card[\"keywords\"])\n",
    "    print(card[\"name\"])\n",
    "    print(card[\"cmc\"])\n",
    "    #print(card[\"rarity\"])\n",
    "    print(card[\"oracle_text\"])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821999ef-c77f-4a85-9bd9-53a69a63ed16",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cards[0][\"set\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007ff055-e568-4389-9856-292355f95d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cardutil import sample_deck\n",
    "a = sample_deck.pop(0)\n",
    "a[\"set\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23eec1a-0066-4119-bbd5-84659d640c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[\"set\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83c3835-eeaa-4cfb-9743-bc6cb544f08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(15):\n",
    "    card = shortened_card_data[i+535]\n",
    "    \n",
    "    if \"subtypes\" in card and card[\"subtypes\"]:\n",
    "        print(\"here\")\n",
    "    for key, value in card.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
